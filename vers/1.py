# -*- coding: utf-8 -*-
# ==============================================================================
#         Streamlit –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è rPPG –ò–∑–º–µ—Ä–µ–Ω–∏—è –ü—É–ª—å—Å–∞ –≤ –†–µ–∞–ª—å–Ω–æ–º –í—Ä–µ–º–µ–Ω–∏
#               (–í—Å–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã) v11 - NN HR Fix + Smoothing
# ==============================================================================
import streamlit as st
import cv2
import numpy as np
import time
import collections
import mediapipe as mp
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.signal import find_peaks, butter, filtfilt, detrend
from sklearn.decomposition import FastICA
import traceback
import os
import warnings

# --- –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π ---
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
APP_TITLE = "rPPG –î–µ—Ç–µ–∫—Ç–æ—Ä –ü—É–ª—å—Å–∞ (–í—Å–µ –ú–µ—Ç–æ–¥—ã + –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ)"
WINDOW_SIZE_SEC = 10; FPS_ESTIMATED = 30; BUFFER_SIZE = WINDOW_SIZE_SEC * FPS_ESTIMATED
ROI_PADDING_FACTOR = 0.1; HR_WINDOW_SEC_ANALYSIS = 6; HR_MIN = 40; HR_MAX = 180
BANDPASS_LOW = 0.7; BANDPASS_HIGH = 4.0; MIN_DETECTION_CONFIDENCE = 0.6
# --- –ù–û–í–û–ï: –§–∞–∫—Ç–æ—Ä —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –ß–°–° (0.0 - –±–µ–∑ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è, ~0.1-0.3 - —É–º–µ—Ä–µ–Ω–Ω–æ–µ, >0.5 - —Å–∏–ª—å–Ω–æ–µ) ---
HR_SMOOTHING_FACTOR = 0.3 # –ß–µ–º –ú–ï–ù–¨–®–ï –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –°–ò–õ–¨–ù–ï–ï —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (–Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ —Ä–µ–∞–∫—Ü–∏—è)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ù–µ–π—Ä–æ—Å–µ—Ç–µ–π ---
NEURAL_NETWORKS = ['SimplePhysNet', 'ImprovedPhysNet', 'HAFNet', 'PhysFormer']
NN_MODEL_PATHS = { # <<< –£–ö–ê–ñ–ò–¢–ï –ü–†–ê–í–ò–õ–¨–ù–´–ï –ü–£–¢–ò –ö –í–ê–®–ò–ú .pth –§–ê–ô–õ–ê–ú! >>>
    'SimplePhysNet': 'SimplePhysNet_final.pth', # –ü—Ä–∏–º–µ—Ä: '/path/to/your/models/SimplePhysNet_final.pth'
    'ImprovedPhysNet': 'ImprovedPhysNet_final.pth',
    'HAFNet': 'HAFNet_final.pth',
    'PhysFormer': 'PhysFormer_final.pth',
}
NN_WINDOW_SIZE_FRAMES = 90; NN_RESIZE_DIM = (64, 64)
PHYSNET_DROPOUT = 0.3
HAFNET_FEATURE_DIM = 32; HAFNET_TRANSFORMER_LAYERS = 1; HAFNET_TRANSFORMER_HEADS = 4; HAFNET_DROPOUT = 0.15
PHYSFORMER_FEATURE_DIM = 64; PHYSFORMER_TRANSFORMER_LAYERS = 2; PHYSFORMER_TRANSFORMER_HEADS = 4; PHYSFORMER_DROPOUT = 0.1

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# --- –ë–õ–û–ö: –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –§—É–Ω–∫—Ü–∏–∏ (–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –ß–°–°) ---
def normalize_signal_np(signal):
    if signal is None or signal.size == 0: return np.array([])
    mean_val = np.mean(signal); std_val = np.std(signal)
    if std_val < 1e-8: return signal - mean_val # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª, –µ—Å–ª–∏ std –±–ª–∏–∑–∫–æ –∫ –Ω—É–ª—é
    return (signal - mean_val) / std_val

def bandpass_filter(signal, fs, low=BANDPASS_LOW, high=BANDPASS_HIGH, order=4):
    if signal is None or signal.size < order * 3 + 1 or fs <= 0: return signal
    nyq = 0.5 * fs; low_f = max(0.01, low); high_f = min(nyq - 0.01, high)
    if low_f >= high_f: return signal # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
    low_norm = low_f / nyq; high_norm = high_f / nyq
    try:
        b, a = butter(order, [low_norm, high_norm], btype='band')
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'gust' –º–µ—Ç–æ–¥ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–∞ –∫—Ä–∞—è—Ö
        y = filtfilt(b, a, signal, method="gust")
    except ValueError as e:
        # print(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {e}, –¥–ª–∏–Ω–∞ —Å–∏–≥–Ω–∞–ª–∞: {len(signal)}, fs: {fs}")
        return signal # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Å–∏–≥–Ω–∞–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    if np.isnan(y).any(): return signal # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π, –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç NaN
    return y

def calculate_hr(signal, fs, window_sec=HR_WINDOW_SEC_ANALYSIS, min_hr=HR_MIN, max_hr=HR_MAX):
    if signal is None or fs <= 0: return np.nan
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—ë –¥–æ—Å—Ç—É–ø–Ω–æ–µ –æ–∫–Ω–æ —Å–∏–≥–Ω–∞–ª–∞ –ò–õ–ò —É–∫–∞–∑–∞–Ω–Ω–æ–µ window_sec, –±–µ—Ä–µ–º –º–µ–Ω—å—à–µ–µ
    effective_window_samples = min(len(signal), int(window_sec * fs))
    if effective_window_samples < fs * 1.0: # –¢—Ä–µ–±—É–µ–º —Ö–æ—Ç—è –±—ã 1 —Å–µ–∫—É–Ω–¥—É –¥–∞–Ω–Ω—ã—Ö
         # print(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ß–°–°: {len(signal)} < {int(fs * 1.0)}")
         return np.nan

    segment = signal[-effective_window_samples:]
    min_dist = int(fs / (max_hr / 60.0)) if max_hr > 0 else 1
    min_dist = max(1, min_dist) # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ö–æ—Ç—è –±—ã 1

    hr = np.nan
    segment_std = np.std(segment)
    if not np.isnan(segment).any() and segment_std > 1e-6: # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏ –Ω–∞–ª–∏—á–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–∏
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–¥–∏–∞–Ω—É –∫–∞–∫ –±–æ–ª–µ–µ —Ä–æ–±–∞—Å—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∏–∫–æ–≤
            segment_median = np.median(segment)
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä prominence –¥–ª—è –±–æ–ª—å—à–µ–π —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç–∏ –∫ —à—É–º—É
            # prominence_threshold = 0.3 * segment_std # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–æ—Ä–æ–≥ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –ø–∏–∫–∞
            # peaks, properties = find_peaks(segment, distance=min_dist, height=segment_median, prominence=prominence_threshold)
            peaks, _ = find_peaks(segment, distance=min_dist, height=segment_median)

            if len(peaks) > 1: # –ù—É–∂–Ω–æ —Ö–æ—Ç—è –±—ã 2 –ø–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —á–∞—Å—Ç–æ—Ç—ã
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –ø–æ –º–µ–¥–∏–∞–Ω–Ω–æ–º—É –∏–Ω—Ç–µ—Ä–≤–∞–ª—É –º–µ–∂–¥—É –ø–∏–∫–∞–º–∏
                # peak_intervals_sec = np.diff(peaks) / fs
                # median_interval = np.median(peak_intervals_sec)
                # if median_interval > 0 and (60.0 / median_interval) >= min_hr and (60.0 / median_interval) <= max_hr:
                #     hr = 60.0 / median_interval

                # –ò–ª–∏ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É
                actual_segment_duration_sec = len(segment) / fs
                peaks_per_sec = len(peaks) / actual_segment_duration_sec if actual_segment_duration_sec > 0 else 0
                hr_calc = peaks_per_sec * 60.0
                # print(f"–ü–∏–∫–∏: {len(peaks)}, –î–ª–∏—Ç: {actual_segment_duration_sec:.2f}—Å, –ß–°–°_—Ä–∞—Å—á: {hr_calc:.1f}")
                if min_hr <= hr_calc <= max_hr:
                    hr = hr_calc
            # else:
                # print(f"–ù–∞–π–¥–µ–Ω–æ –ø–∏–∫–æ–≤: {len(peaks)}")

        except Exception as e:
            # print(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ß–°–°: {e}")
            pass # –ü—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º NaN –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
    # else:
        # print(f"–°–∏–≥–º–µ–Ω—Ç –Ω–µ–≤–∞–ª–∏–¥–µ–Ω –¥–ª—è –ß–°–°: std={segment_std:.4f}, NaN={np.isnan(segment).any()}")

    return hr

# --- –ë–õ–û–ö: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ú–µ—Ç–æ–¥—ã (POS, CHROM, ICA) ---
def chrom_method(rgb_buffer):
    if rgb_buffer is None or rgb_buffer.shape[0]<2 or rgb_buffer.shape[1]!=3: return np.array([])
    std_rgb=np.std(rgb_buffer,axis=0,keepdims=True); std_rgb[std_rgb<1e-8]=1.0; RGB_std=rgb_buffer/std_rgb
    X=3*RGB_std[:,0]-2*RGB_std[:,1]; Y=1.5*RGB_std[:,0]+RGB_std[:,1]-1.5*RGB_std[:,2]
    std_X=np.std(X); std_Y=np.std(Y); alpha=std_X/(std_Y+1e-8) if std_Y>1e-8 else 1.0
    chrom_signal=X-alpha*Y;
    try: return detrend(chrom_signal)
    except ValueError: return chrom_signal - np.mean(chrom_signal)

def pos_method(rgb_buffer):
    if rgb_buffer is None or rgb_buffer.shape[0]<2 or rgb_buffer.shape[1]!=3: return np.array([])
    mean_rgb=np.mean(rgb_buffer,axis=0,keepdims=True); mean_rgb[mean_rgb<1e-8]=1.0; rgb_norm=rgb_buffer/mean_rgb
    try: rgb_detrended=detrend(rgb_norm,axis=0)
    except ValueError: rgb_detrended=rgb_norm-np.mean(rgb_norm,axis=0,keepdims=True)
    proj_mat=np.array([[0,1,-1],[-2,1,1]]); proj_sig=np.dot(rgb_detrended,proj_mat.T); std_dev=np.std(proj_sig,axis=0)
    if std_dev.shape[0]<2: alpha=1.0
    elif std_dev[0]<1e-8: alpha=1.0
    else: alpha=std_dev[1]/(std_dev[0]+1e-8)
    pos_signal=proj_sig[:,0]+alpha*proj_sig[:,1];
    try: return detrend(pos_signal)
    except ValueError: return pos_signal - np.mean(pos_signal)

def ica_method(rgb_buffer, fs_approx=30):
    if rgb_buffer is None or rgb_buffer.shape[0] < 3 or rgb_buffer.shape[1] != 3: return np.array([])
    try: rgb_detrended=detrend(rgb_buffer,axis=0)
    except ValueError: rgb_detrended=rgb_buffer-np.mean(rgb_buffer,axis=0,keepdims=True)
    n_components=3
    try: # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–Ω–≥–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫ –≤ ICA
        cov_matrix = np.cov(rgb_detrended.T)
        rank = np.linalg.matrix_rank(cov_matrix)
        n_components = max(1, rank)
        if n_components == 1: # –ï—Å–ª–∏ —Ä–∞–Ω–≥ 1, ICA –Ω–µ –Ω—É–∂–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º—ã–π –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω—ã–π –∫–∞–Ω–∞–ª
            stds = np.std(rgb_detrended, axis=0)
            if len(stds) > 0 and np.max(stds) > 1e-8:
                best_channel = rgb_detrended[:, np.argmax(stds)]
                try: return detrend(best_channel)
                except ValueError: return best_channel - np.mean(best_channel)
            else: return np.zeros(rgb_buffer.shape[0]) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–∏, –µ—Å–ª–∏ –Ω–µ—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
        # print(f"ICA: n_components = {n_components}")
    except Exception as e_rank:
        # print(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–Ω–≥–∞ –¥–ª—è ICA: {e_rank}")
        pass # –ò—Å–ø–æ–ª—å–∑—É–µ–º n_components=3 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    S_ = np.array([]) # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    try:
        # –£–º–µ–Ω—å—à–∞–µ–º max_iter –∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º tol –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è, –æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ FPS –Ω–∏–∑–∫–∏–π
        ica = FastICA(n_components=n_components, random_state=42, max_iter=250, tol=0.08, whiten='unit-variance')
        S_ = ica.fit_transform(rgb_detrended)
        if S_.shape[1] != n_components:
             # print(f"Warning ICA: –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—ã—Ö–æ–¥–∞ ICA ({S_.shape[1]} != {n_components})")
             return np.array([]) # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—ã—Ö–æ–¥–∞ ICA
    except Exception as e:
        # print(f"Warning ICA fit_transform: {e}")
        return np.array([]) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ –ø—Ä–∏ –æ—à–∏–±–∫–µ ICA

    best_idx=-1; max_power=-1; low_f=BANDPASS_LOW; high_f=BANDPASS_HIGH
    for i in range(S_.shape[1]):
        sig=S_[:,i]
        if len(sig)<2 or np.std(sig)<1e-8: continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –±–µ–∑ –≤–∞—Ä–∏–∞—Ü–∏–∏
        try:
            # –í—ã—á–∏—Å–ª—è–µ–º –º–æ—â–Ω–æ—Å—Ç—å –≤ —á–∞—Å—Ç–æ—Ç–Ω–æ–π –ø–æ–ª–æ—Å–µ –ø—É–ª—å—Å–∞
            fft_win=sig*np.hanning(len(sig)) # –û–∫–Ω–æ –•–∞–Ω–Ω–∞ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —É—Ç–µ—á–∫–∏ —Å–ø–µ–∫—Ç—Ä–∞
            fft_v=np.fft.rfft(fft_win)
            fft_f=np.fft.rfftfreq(len(sig),1.0/fs_approx if fs_approx > 0 else 1.0/FPS_ESTIMATED)
            p_s=np.abs(fft_v)**2 # –°–ø–µ–∫—Ç—Ä –º–æ—â–Ω–æ—Å—Ç–∏
            mask=(fft_f>=low_f)&(fft_f<=high_f)
            if np.any(mask):
                p_band=np.mean(p_s[mask])
                if p_band > max_power: max_power=p_band; best_idx=i
        except Exception as e_fft:
            # print(f"–û—à–∏–±–∫–∞ FFT –≤ ICA: {e_fft}")
            continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ FFT

    if best_idx == -1: # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –ø–æ –º–æ—â–Ω–æ—Å—Ç–∏ FFT, –≤—ã–±–∏—Ä–∞–µ–º –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        stds = np.std(S_,axis=0)
        if len(stds) > 0 and np.max(stds) > 1e-8:
             best_idx = np.argmax(stds)
             # print("ICA: –í—ã–±—Ä–∞–Ω–æ –ø–æ std")
        else:
             # print("ICA: –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç")
             return np.array([]) # –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç

    # print(f"ICA: –í—ã–±—Ä–∞–Ω –∫–æ–º–ø–æ–Ω–µ–Ω—Ç {best_idx}")
    selected_component = S_[:, best_idx]
    try: return detrend(selected_component)
    except ValueError: return selected_component - np.mean(selected_component)


# --- –ë–õ–û–ö: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ú–æ–¥–µ–ª–µ–π –ù–µ–π—Ä–æ–Ω–Ω—ã—Ö –°–µ—Ç–µ–π ---
# (–ö–ª–∞—Å—Å—ã SimplePhysNet, ImprovedPhysNet, PositionalEncoding, PhysFormer3DStem,
# TemporalDifferenceModule, PhysFormer, HAFNet - –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫–∞–∫ –≤ –≤–∞—à–µ–º –∫–æ–¥–µ)
class SimplePhysNet(nn.Module):
    def __init__(self,in_channels=3,out_len=NN_WINDOW_SIZE_FRAMES): super().__init__(); self.encoder=nn.Sequential(nn.Conv3d(in_channels,32,(1,5,5),padding=(0,2,2)),nn.BatchNorm3d(32),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(32,64,(3,3,3),padding=1),nn.BatchNorm3d(64),nn.ReLU(),nn.MaxPool3d((1,2,2))); self.decoder=nn.Sequential(nn.Conv3d(64,1,kernel_size=1),nn.AdaptiveAvgPool3d((out_len,1,1)))
    def forward(self,x): x=self.encoder(x); x=self.decoder(x); x=x.squeeze(-1).squeeze(-1).squeeze(1); return x
class ImprovedPhysNet(nn.Module):
    def __init__(self,in_channels=3,out_len=NN_WINDOW_SIZE_FRAMES,dropout=PHYSNET_DROPOUT): super().__init__(); self.encoder=nn.Sequential(nn.Conv3d(in_channels,32,(1,5,5),padding=(0,2,2)),nn.BatchNorm3d(32),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(32,64,(3,3,3),padding=1),nn.BatchNorm3d(64),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(64,128,(3,3,3),padding=1),nn.BatchNorm3d(128),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Dropout3d(dropout)); self.decoder=nn.Sequential(nn.Conv3d(128,1,kernel_size=1),nn.AdaptiveAvgPool3d((out_len,1,1)))
    def forward(self,x): x=self.encoder(x); x=self.decoder(x); x=x.squeeze(-1).squeeze(-1).squeeze(1); return x
class PositionalEncoding(nn.Module):
    def __init__(self,d_model,max_len=512): super().__init__(); pos=torch.arange(max_len).unsqueeze(1); div=torch.exp(torch.arange(0,d_model,2)*(-np.log(10000.0)/d_model)); pe=torch.zeros(max_len,d_model); pe[:,0::2]=torch.sin(pos*div); pe[:,1::2]=torch.cos(pos*div); self.register_buffer('pe',pe)
    def forward(self,x): return x+self.pe[:x.size(1)].unsqueeze(0)
class PhysFormer3DStem(nn.Module):
    def __init__(self,in_channels=3,feature_dim=64): super().__init__(); self.feature_dim_arg = feature_dim; self.stem=nn.Sequential(nn.Conv3d(in_channels,16,(1,5,5),padding=(0,2,2)),nn.BatchNorm3d(16),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(16,32,(3,3,3),padding=1),nn.BatchNorm3d(32),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(32,feature_dim,(3,3,3),padding=1),nn.BatchNorm3d(feature_dim),nn.ReLU(),nn.AdaptiveAvgPool3d((None,1,1)))
    def forward(self,x): x=self.stem(x); x=x.squeeze(-1).squeeze(-1); x=x.permute(0,2,1); return x
class TemporalDifferenceModule(nn.Module):
    def __init__(self): super().__init__()
    def forward(self,x): diff=x[:,1:,:]-x[:,:-1,:]; diff=F.pad(diff,(0,0,1,0),"constant",0); return diff
class PhysFormer(nn.Module):
    def __init__(self,in_channels=3,feature_dim=PHYSFORMER_FEATURE_DIM,num_layers=PHYSFORMER_TRANSFORMER_LAYERS,num_heads=PHYSFORMER_TRANSFORMER_HEADS,dropout=PHYSFORMER_DROPOUT,max_len=NN_WINDOW_SIZE_FRAMES):
        super().__init__(); self.feat_ext=PhysFormer3DStem(in_channels,feature_dim); self.tdm=TemporalDifferenceModule(); self.pos_enc=PositionalEncoding(feature_dim,max_len)
        enc_l=nn.TransformerEncoderLayer(d_model=feature_dim,nhead=num_heads,dim_feedforward=feature_dim*2,dropout=dropout,activation='relu',batch_first=True)
        self.transformer=nn.TransformerEncoder(enc_l,num_layers=num_layers,norm=nn.LayerNorm(feature_dim)); self.head=nn.Sequential(nn.LayerNorm(feature_dim),nn.Linear(feature_dim,1))
    def forward(self,x): feat=self.feat_ext(x); diff=self.tdm(feat); diff_pos=self.pos_enc(diff); z=self.transformer(diff_pos); out=self.head(z); return out.squeeze(-1)
class HAFNet(nn.Module):
    def __init__(self,in_channels=3,feature_dim=HAFNET_FEATURE_DIM,nhead=HAFNET_TRANSFORMER_HEADS,num_encoder_layers=HAFNET_TRANSFORMER_LAYERS,dropout=HAFNET_DROPOUT,max_len=NN_WINDOW_SIZE_FRAMES):
        super().__init__(); self.cnn_stem=PhysFormer3DStem(in_channels,feature_dim); self.pos_enc=PositionalEncoding(feature_dim,max_len)
        enc_l=nn.TransformerEncoderLayer(d_model=feature_dim,nhead=nhead,dim_feedforward=feature_dim*2,dropout=dropout,activation='relu',batch_first=True)
        self.transformer_enc=nn.TransformerEncoder(enc_l,num_layers=num_encoder_layers,norm=nn.LayerNorm(feature_dim)); self.head=nn.Sequential(nn.LayerNorm(feature_dim),nn.Linear(feature_dim,1))
    def forward(self,x): feat=self.cnn_stem(x); feat_pos=self.pos_enc(feat); mem=self.transformer_enc(feat_pos); out=self.head(mem); return out.squeeze(-1)

def get_model_instance(model_name, model_path):
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ—Å–∞."""
    model_class_map = {
        "SimplePhysNet": SimplePhysNet, "ImprovedPhysNet": ImprovedPhysNet,
        "HAFNet": HAFNet, "PhysFormer": PhysFormer
    }
    model_class = model_class_map.get(model_name)
    if not model_class:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–∏ –¥–ª—è {model_name}")

    model = model_class().to(device) # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
    try:
        state_dict = torch.load(model_path, map_location=device)
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–π, –µ—Å–ª–∏ state_dict —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å –¥—Ä—É–≥–∏–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'module.')
        if all(k.startswith('module.') for k in state_dict.keys()):
             state_dict = {k[len('module.'):]: v for k, v in state_dict.items()}

        model_dict = model.state_dict()
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –ø–æ –∏–º–µ–Ω–∏ –∏ —Ä–∞–∑–º–µ—Ä—É —Å–ª–æ–∏
        state_dict = {k: v for k, v in state_dict.items() if k in model_dict and model_dict[k].size() == v.size()}
        if not state_dict:
             print(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö —Å–ª–æ–µ–≤ –≤ state_dict –¥–ª—è {model_name} –∏–∑ {model_path}")
             return None # –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å–∞

        model_dict.update(state_dict)
        model.load_state_dict(model_dict, strict=False) # strict=False –¥–æ–ø—É—Å–∫–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
        model.eval() # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
        print(f"  –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
        return model
    except FileNotFoundError:
        print(f"  –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {model_path}")
        return None
    except Exception as e:
        print(f"  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤ –¥–ª—è {model_name} –∏–∑ {model_path}: {e}")
        traceback.print_exc()
        return None


# --- –§—É–Ω–∫—Ü–∏—è –ó–∞–≥—Ä—É–∑–∫–∏ –ú–æ–¥–µ–ª–µ–π –ù–° —Å –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º ---
@st.cache_resource # –ö–µ—à–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä MP
def load_resources():
    models = {}
    print("--- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –ù–° ---")
    for name in NEURAL_NETWORKS:
        path = NN_MODEL_PATHS.get(name)
        if not path:
            print(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è –º–æ–¥–µ–ª–∏ {name}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue

        model_file_exists = os.path.exists(path)
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ '{path}' –¥–ª—è –º–æ–¥–µ–ª–∏ {name}: {'–ù–∞–π–¥–µ–Ω' if model_file_exists else '–ù–ï –ù–ê–ô–î–ï–ù'}")

        if model_file_exists:
            model_instance = get_model_instance(name, path)
            if model_instance:
                models[name] = model_instance
        else:
            print(f"  –ü—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ {name}, —Ç.–∫. —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    print(f"--- –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(models)} –ù–° –º–æ–¥–µ–ª–µ–π ---")

    print("--- –ó–∞–≥—Ä—É–∑–∫–∞ MediaPipe ---")
    face_detector = None
    try:
        mp_face_detection = mp.solutions.face_detection
        # Model_selection=0 –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –¥–∏—Å—Ç–∞–Ω—Ü–∏–π (<2–º), =1 –¥–ª—è –¥–∞–ª—å–Ω–∏—Ö (<5–º)
        face_detector = mp_face_detection.FaceDetection(min_detection_confidence=MIN_DETECTION_CONFIDENCE, model_selection=0)
        print("MediaPipe Face Detection —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MediaPipe: {e}")
        traceback.print_exc()
        # –ï—Å–ª–∏ MediaPipe –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —Å–º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å MediaPipe Face Detection: {e}. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å.")
        st.stop() # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Streamlit

    return models, face_detector

# --- –û—Å–Ω–æ–≤–Ω–∞—è –§—É–Ω–∫—Ü–∏—è –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
def run_rppg_app():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –†–µ—Å—É—Ä—Å–æ–≤ ---
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ load_resources
    loaded_nn_models, face_detector = load_resources()
    # face_detector –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –Ω–∞ None –≤–Ω—É—Ç—Ä–∏ load_resources, –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è, –µ—Å–ª–∏ –æ–Ω None

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
    available_methods = ["POS", "CHROM", "ICA"] + sorted(list(loaded_nn_models.keys()))
    if not available_methods:
         st.error("–û—à–∏–±–∫–∞: –ù–µ –¥–æ—Å—Ç—É–ø–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ rPPG (–Ω–∏ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö, –Ω–∏ –ù–°).")
         return

    selected_method = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è:", available_methods, index=0, key="method_select") # –ù–∞—á–∏–Ω–∞–µ–º —Å POS

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ö–∞–º–µ—Ä—ã ---
    cap = None
    camera_indices = [0, 1, 2] # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–∞–º–µ—Ä—ã
    for idx in camera_indices:
        try:
            cap = cv2.VideoCapture(idx)
            if cap.isOpened():
                print(f"–í–µ–±-–∫–∞–º–µ—Ä–∞ —É—Å–ø–µ—à–Ω–æ –æ—Ç–∫—Ä—ã—Ç–∞ (–∏–Ω–¥–µ–∫—Å {idx}).")
                break
            else:
                 cap.release() # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º, –µ—Å–ª–∏ –Ω–µ –æ—Ç–∫—Ä—ã–ª–∞—Å—å
                 cap = None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É {idx}: {e}")
            if cap: cap.release(); cap=None

    if cap is None:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–µ–±-–∫–∞–º–µ—Ä—É –Ω–∏ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ (0, 1, 2). –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∫–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥—Ä—É–≥–∏–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º.")
        return

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë—É—Ñ–µ—Ä–æ–≤ –∏ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ session_state ---
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º st.session_state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏ —Å–∫—Ä–∏–ø—Ç–∞ Streamlit
    if 'initialized' not in st.session_state:
        st.session_state.mean_rgb_buffer = collections.deque(maxlen=BUFFER_SIZE)
        st.session_state.rppg_signal_buffer = collections.deque(maxlen=BUFFER_SIZE) # –ë—É—Ñ–µ—Ä –¥–ª—è –ö–õ–ê–°–°–ò–ß–ï–°–ö–ò–• —Å–∏–≥–Ω–∞–ª–æ–≤
        st.session_state.timestamps = collections.deque(maxlen=BUFFER_SIZE)
        st.session_state.nn_frame_buffer = collections.deque(maxlen=NN_WINDOW_SIZE_FRAMES)
        st.session_state.current_hr = np.nan # –¢–µ–∫—É—â–µ–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–µ (—Å–≥–ª–∞–∂–µ–Ω–Ω–æ–µ) –∑–Ω–∞—á–µ–Ω–∏–µ –ß–°–°
        st.session_state.last_fps_time = time.time()
        st.session_state.frame_count_for_fps = 0
        st.session_state.last_signal_time = time.time() # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è ROI
        st.session_state.nn_ready_to_predict = False # –§–ª–∞–≥ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –±—É—Ñ–µ—Ä–∞ –ù–°
        st.session_state.last_method = selected_method
        st.session_state.initialized = True
        print("–°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ.")

    # –°–±—Ä–æ—Å –±—É—Ñ–µ—Ä–æ–≤ –ø—Ä–∏ —Å–º–µ–Ω–µ –º–µ—Ç–æ–¥–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–æ)
    if selected_method != st.session_state.last_method:
        print(f"–ú–µ—Ç–æ–¥ –∏–∑–º–µ–Ω–µ–Ω —Å {st.session_state.last_method} –Ω–∞ {selected_method}. –°–±—Ä–æ—Å –±—É—Ñ–µ—Ä–æ–≤.")
        st.session_state.mean_rgb_buffer.clear()
        st.session_state.rppg_signal_buffer.clear()
        st.session_state.timestamps.clear()
        st.session_state.nn_frame_buffer.clear()
        st.session_state.current_hr = np.nan
        st.session_state.nn_ready_to_predict = False
        st.session_state.last_method = selected_method

    # --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
    col1, col2 = st.columns([3, 1]) # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
    with col1:
        stframe = st.empty() # Placeholder –¥–ª—è –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞
    with col2:
        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –†–µ–∑—É–ª—å—Ç–∞—Ç")
        st.write(f"–ú–µ—Ç–æ–¥: **{selected_method}**")
        # Placeholder'—ã –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        hr_placeholder = st.empty()
        fps_placeholder = st.empty()
        signal_placeholder = st.empty() # –î–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ —Å–∏–≥–Ω–∞–ª–∞
        status_placeholder = st.empty() # –î–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π –æ —Å—Ç–∞—Ç—É—Å–µ (–ª–∏—Ü–æ –∏ —Ç.–¥.)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        hr_placeholder.metric("–¢–µ–∫—É—â–∏–π –ü—É–ª—å—Å (—É–¥/–º–∏–Ω)", "–û–∂–∏–¥–∞–Ω–∏–µ...")
        fps_placeholder.write("–ö–∞–º–µ—Ä–∞ FPS: ...")

    # --- –ì–ª–∞–≤–Ω—ã–π –¶–∏–∫–ª ---
    is_running = True
    print("–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    while is_running:
        loop_start_time = time.time()
        try:
            ret, frame = cap.read()
            if not ret or frame is None or frame.size == 0:
                status_placeholder.warning("–ü—Ä–æ–±–ª–µ–º–∞ —Å —á—Ç–µ–Ω–∏–µ–º –∫–∞–¥—Ä–∞...", icon="‚ö†Ô∏è")
                time.sleep(0.1) # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É, –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è
                if time.time() - st.session_state.last_fps_time > 5.0: # –ï—Å–ª–∏ 5 —Å–µ–∫—É–Ω–¥ –Ω–µ—Ç –∫–∞–¥—Ä–æ–≤
                    print("–ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É...")
                    if cap: cap.release()
                    cap = cv2.VideoCapture(0) # –ü—ã—Ç–∞–µ–º—Å—è —Å–Ω–æ–≤–∞ —Å 0
                    if not cap.isOpened():
                         st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É.")
                         is_running = False; continue
                    st.session_state.last_fps_time = time.time() # –°–±—Ä–æ—Å —Ç–∞–π–º–µ—Ä–∞ FPS
                continue

            current_time = time.time()
            st.session_state.timestamps.append(current_time)

            # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ö–∞–¥—Ä–∞ (MediaPipe) ---
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_rgb.flags.writeable = False # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è MediaPipe
            if frame_rgb.dtype != np.uint8: frame_rgb = frame_rgb.astype(np.uint8)

            results = face_detector.process(frame_rgb)
            frame_rgb.flags.writeable = True # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ (—Ö–æ—Ç—è –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –≤—ã–≤–æ–¥–∞)

            height, width, _ = frame.shape
            face_found = False
            roi_display = frame.copy() # –ö–æ–ø–∏—è –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è ROI

            if results.detections:
                # –ë–µ—Ä–µ–º —Å–∞–º–æ–µ —É–≤–µ—Ä–µ–Ω–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ
                detection = sorted(results.detections, key=lambda x: x.score[0], reverse=True)[0]
                bboxC = detection.location_data.relative_bounding_box
                if bboxC and detection.score[0] > MIN_DETECTION_CONFIDENCE: # –î–æ–ø. –ø—Ä–æ–≤–µ—Ä–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    xmin=int(bboxC.xmin*width); ymin=int(bboxC.ymin*height); w=int(bboxC.width*width); h=int(bboxC.height*height)
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã
                    pad_w=int(w*ROI_PADDING_FACTOR); pad_h=int(h*ROI_PADDING_FACTOR)
                    x1=max(0,xmin-pad_w); y1=max(0,ymin-pad_h); x2=min(width,xmin+w+pad_w); y2=min(height,ymin+h+pad_h)

                    if y2 > y1 and x2 > x1: # –í–∞–ª–∏–¥–Ω—ã–π ROI
                        face_found = True
                        roi = frame[y1:y2, x1:x2]
                        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ü–≤–µ—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
                        mean_bgr_roi = np.mean(roi, axis=(0, 1))
                        st.session_state.mean_rgb_buffer.append(mean_bgr_roi[::-1]) # BGR -> RGB
                        st.session_state.last_signal_time = current_time # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è

                        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π ROI –¥–ª—è –ù–°
                        if selected_method in loaded_nn_models:
                            try:
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º INTER_LINEAR –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                                roi_resized_nn = cv2.resize(roi, NN_RESIZE_DIM, interpolation=cv2.INTER_LINEAR)
                                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [-1, 1]
                                roi_norm = (roi_resized_nn / 255.0) * 2.0 - 1.0
                                # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ (C, H, W) –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä –ù–°
                                st.session_state.nn_frame_buffer.append(roi_norm.transpose(2, 0, 1))
                            except cv2.error as e_resize:
                                print(f"–û—à–∏–±–∫–∞ cv2.resize/–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –ù–°: {e_resize}")
                                pass # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç—Ç–æ–≥–æ –∫–∞–¥—Ä–∞ –≤ –±—É—Ñ–µ—Ä –ù–°

                        # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫ –Ω–∞ –∫–æ–ø–∏–∏ –∫–∞–¥—Ä–∞
                        cv2.rectangle(roi_display, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # –£–ø—Ä–∞–≤–ª—è–µ–º —Ñ–ª–∞–≥–æ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ù–°
            if face_found:
                st.session_state.nn_ready_to_predict = (selected_method in loaded_nn_models and len(st.session_state.nn_frame_buffer) == NN_WINDOW_SIZE_FRAMES)
                if not st.session_state.nn_ready_to_predict and selected_method in loaded_nn_models:
                     status_placeholder.info(f"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {selected_method}: {len(st.session_state.nn_frame_buffer)}/{NN_WINDOW_SIZE_FRAMES} –∫–∞–¥—Ä–æ–≤", icon="‚è≥")
                elif st.session_state.nn_ready_to_predict:
                     status_placeholder.success("–ë—É—Ñ–µ—Ä –ù–° –≥–æ—Ç–æ–≤ –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é!", icon="‚úÖ")
                else: # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥, –ª–∏—Ü–æ –Ω–∞–π–¥–µ–Ω–æ
                     status_placeholder.empty() # –£–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            else:
                # –ï—Å–ª–∏ –ª–∏—Ü–æ –ø–æ—Ç–µ—Ä—è–Ω–æ, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –ù–° –∏ –æ—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –ù–° (—á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
                if selected_method in loaded_nn_models:
                     st.session_state.nn_frame_buffer.clear()
                st.session_state.nn_ready_to_predict = False
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –ª–∏—Ü–æ –Ω–µ –≤–∏–¥–Ω–æ –¥–æ–ª—å—à–µ ~1 —Å–µ–∫—É–Ω–¥—ã
                if time.time() - st.session_state.last_signal_time > 1.0:
                     status_placeholder.info("–õ–∏—Ü–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ...", icon="üö´")


            # --- –†–∞—Å—á–µ—Ç rPPG –°–∏–≥–Ω–∞–ª–∞ –∏ –ß–°–° ---
            calculated_hr_this_step = np.nan # –ß–°–°, —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–∞—è –Ω–∞ —ç—Ç–æ–º —à–∞–≥–µ (–¥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è)
            actual_fps = FPS_ESTIMATED # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if len(st.session_state.timestamps) > 10:
                 # –û—Ü–µ–Ω–∏–≤–∞–µ–º FPS –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º ~10 –∫–∞–¥—Ä–∞–º
                 time_diff = st.session_state.timestamps[-1] - st.session_state.timestamps[-10]
                 if time_diff > 0.01: actual_fps = 9 / time_diff # 9 –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É 10 —Ç–æ—á–∫–∞–º–∏
                 actual_fps = max(1.0, min(actual_fps, 60.0)) # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏

            signal_processed_success = False
            current_rppg_signal_for_plot = None # –°–∏–≥–Ω–∞–ª –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ

            # --- –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã ---
            if selected_method in ["POS", "CHROM", "ICA"]:
                 # –¢—Ä–µ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö RGB
                 min_len_classical = int(BUFFER_SIZE * 0.3) # –ù–∞—á–∏–Ω–∞–µ–º —Å—á–∏—Ç–∞—Ç—å —Ä–∞–Ω—å—à–µ
                 if selected_method == "ICA": min_len_classical = int(BUFFER_SIZE * 0.7) # ICA —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ

                 if len(st.session_state.mean_rgb_buffer) > min_len_classical:
                    rgb_data = np.array(st.session_state.mean_rgb_buffer)
                    rppg_signal_raw = np.array([])
                    try:
                        if selected_method == "POS": rppg_signal_raw = pos_method(rgb_data)
                        elif selected_method == "CHROM": rppg_signal_raw = chrom_method(rgb_data)
                        elif selected_method == "ICA": rppg_signal_raw = ica_method(rgb_data, actual_fps)
                    except Exception as e_method:
                        print(f"–û—à–∏–±–∫–∞ –º–µ—Ç–æ–¥–∞ {selected_method}: {e_method}")
                        traceback.print_exc()

                    if rppg_signal_raw is not None and rppg_signal_raw.size > 1:
                        rppg_norm = normalize_signal_np(rppg_signal_raw)
                        rppg_filt = bandpass_filter(rppg_norm, actual_fps)

                        if rppg_filt is not None and rppg_filt.size > 1:
                            # –û–±–Ω–æ–≤–ª—è–µ–º –±—É—Ñ–µ—Ä rPPG –¥–ª—è –∫–ª–∞—Å—Å–∏–∫–∏ (–¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
                            num_processed_in_batch = len(rppg_filt) # –î–ª–∏–Ω–∞ –≤—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
                            num_already_in_buffer = len(st.session_state.rppg_signal_buffer)
                            num_expected_from_rgb = len(rgb_data)

                            # –°–∫–æ–ª—å–∫–æ –ù–û–í–´–• —Ç–æ—á–µ–∫ –¥–æ–ª–∂–Ω–æ –±—ã–ª–æ –ø–æ—è–≤–∏—Ç—å—Å—è (–ø—Ä–∏–º–µ—Ä–Ω–æ)
                            num_new_points = num_expected_from_rgb - num_already_in_buffer

                            if num_new_points > 0 and len(rppg_filt) >= num_new_points:
                                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ "–Ω–æ–≤—ã–µ" —Ç–æ—á–∫–∏ –∏–∑ –∫–æ–Ω—Ü–∞ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
                                st.session_state.rppg_signal_buffer.extend(rppg_filt[-num_new_points:])
                            elif len(rppg_filt) > num_already_in_buffer :
                                # –ï—Å–ª–∏ —Ä–∞—Å—á–µ—Ç –Ω–µ —Å—Ö–æ–¥–∏—Ç—Å—è, –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ, —á—Ç–æ –Ω–æ–≤–µ–µ
                                st.session_state.rppg_signal_buffer.extend(rppg_filt[num_already_in_buffer:])
                            elif len(rppg_filt)>0 and num_already_in_buffer==0:
                                 st.session_state.rppg_signal_buffer.extend(rppg_filt) # –ü–µ—Ä–≤—ã–π —Ä–∞–∑

                            signal_processed_success = True
                            current_rppg_signal_for_plot = np.array(st.session_state.rppg_signal_buffer)

                            # –†–∞—Å—á–µ—Ç –ß–°–° –¥–ª—è –∫–ª–∞—Å—Å–∏–∫–∏ (–∏–∑ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–≥–æ –±—É—Ñ–µ—Ä–∞ rppg_signal_buffer)
                            min_len_hr = int(HR_WINDOW_SEC_ANALYSIS * actual_fps * 0.8) # –¢—Ä–µ–±—É–µ–º 80% –æ–∫–Ω–∞
                            if len(st.session_state.rppg_signal_buffer) > min_len_hr:
                                hr_val = calculate_hr(current_rppg_signal_for_plot, actual_fps, window_sec=HR_WINDOW_SEC_ANALYSIS)
                                if not np.isnan(hr_val):
                                    calculated_hr_this_step = hr_val


            # --- –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã ---
            elif selected_method in loaded_nn_models:
                 # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –±—É—Ñ–µ—Ä –ù–° –ü–û–õ–û–ù
                 if st.session_state.nn_ready_to_predict:
                    rppg_signal_raw_nn = np.array([])
                    nn_predict_start_time = time.time()
                    try:
                        model_instance = loaded_nn_models[selected_method]
                        nn_input_numpy = np.array(st.session_state.nn_frame_buffer) # (T, C, H, W)
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (C, T, H, W)
                        nn_input_permuted = nn_input_numpy.transpose(1, 0, 2, 3) # (C, T, H, W)
                        input_tensor = torch.from_numpy(nn_input_permuted).float().unsqueeze(0).to(device) # (B=1, C, T, H, W)

                        # --- –ò–ù–§–ï–†–ï–ù–° (–∑–¥–µ—Å—å –æ—Å–Ω–æ–≤–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞) ---
                        with torch.no_grad():
                            rppg_signal_raw_nn = model_instance(input_tensor).squeeze().cpu().numpy()
                        # -----------------------------------------
                        nn_predict_duration = time.time() - nn_predict_start_time
                        # print(f"NN ({selected_method}) prediction time: {nn_predict_duration:.3f}s")

                    except Exception as e_method:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ù–° {selected_method}: {e_method}")
                        traceback.print_exc()

                    # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–∞ –ù–° –∏ —Ä–∞—Å—á–µ—Ç –ß–°–° ---
                    if rppg_signal_raw_nn is not None and rppg_signal_raw_nn.size > 1:
                        rppg_norm_nn = normalize_signal_np(rppg_signal_raw_nn)
                        # –§–∏–ª—å—Ç—Ä—É–µ–º –í–ï–°–¨ –≤—ã—Ö–æ–¥ –ù–°
                        rppg_filt_nn = bandpass_filter(rppg_norm_nn, actual_fps) # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π FPS

                        if rppg_filt_nn is not None and rppg_filt_nn.size > 1:
                            signal_processed_success = True
                            current_rppg_signal_for_plot = rppg_filt_nn # –ë–µ—Ä–µ–º –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –∏–º–µ–Ω–Ω–æ –≤—ã—Ö–æ–¥ –ù–°

                            # –†–∞—Å—á–µ—Ç –ß–°–° –ù–ê–ü–†–Ø–ú–£–Æ –∏–∑ –≤—ã—Ö–æ–¥–∞ –ù–° (`rppg_filt_nn`)
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–∫–Ω–∞ –ù–°
                            nn_window_duration_sec = NN_WINDOW_SIZE_FRAMES / actual_fps if actual_fps > 5 else (NN_WINDOW_SIZE_FRAMES / FPS_ESTIMATED)
                            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å—å –¥–æ—Å—Ç—É–ø–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ù–°
                            analysis_win_sec_nn = nn_window_duration_sec

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ß–°–°
                            # –¢—Ä–µ–±—É–µ–º —Ö–æ—Ç—è –±—ã ~1.5 —Å–µ–∫—É–Ω–¥—ã —Å–∏–≥–Ω–∞–ª–∞
                            min_samples_nn_hr = int(actual_fps * 1.5)
                            if len(rppg_filt_nn) >= min_samples_nn_hr:
                                hr_val = calculate_hr(rppg_filt_nn, actual_fps, window_sec=analysis_win_sec_nn)
                                if not np.isnan(hr_val):
                                    calculated_hr_this_step = hr_val

                    # --- –û—á–∏—Å—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞ –ù–° –ü–û–°–õ–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ---
                    st.session_state.nn_frame_buffer.clear()
                    st.session_state.nn_ready_to_predict = False # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥


            # --- –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∏ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ß–°–° ---
            smoothed_hr = st.session_state.current_hr # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            if not np.isnan(calculated_hr_this_step):
                 # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–æ–µ –≤–∞–ª–∏–¥–Ω–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –ò–õ–ò –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –±—ã–ª–æ NaN
                 if np.isnan(st.session_state.current_hr):
                      smoothed_hr = calculated_hr_this_step
                 else:
                      # –ü—Ä–∏–º–µ–Ω—è–µ–º EMA —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
                      smoothed_hr = (HR_SMOOTHING_FACTOR * calculated_hr_this_step +
                                   (1 - HR_SMOOTHING_FACTOR) * st.session_state.current_hr)
                 st.session_state.current_hr = smoothed_hr # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ —Å–≥–ª–∞–∂–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

            # --- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ---
            # 1. –ß–°–°
            hr_display = f"{st.session_state.current_hr:.1f}" if not np.isnan(st.session_state.current_hr) else "..."
            hr_placeholder.metric("–¢–µ–∫—É—â–∏–π –ü—É–ª—å—Å (—É–¥/–º–∏–Ω)", hr_display)

            # 2. FPS
            st.session_state.frame_count_for_fps += 1
            elapsed_time = time.time() - st.session_state.last_fps_time
            if elapsed_time > 1.0: # –û–±–Ω–æ–≤–ª—è–µ–º FPS —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É
                display_fps = st.session_state.frame_count_for_fps / elapsed_time
                fps_placeholder.write(f"–ö–∞–º–µ—Ä–∞ FPS: {display_fps:.1f} | –û–±—Ä–∞–±. FPS: {actual_fps:.1f}")
                # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–æ–≤ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
                st.session_state.last_fps_time = time.time()
                st.session_state.frame_count_for_fps = 0

            # 3. –ì—Ä–∞—Ñ–∏–∫ —Å–∏–≥–Ω–∞–ª–∞
            if signal_processed_success and current_rppg_signal_for_plot is not None and current_rppg_signal_for_plot.size > 10:
                 # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Ç–æ—á–µ–∫ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, BUFFER_SIZE)
                 plot_data = current_rppg_signal_for_plot[-BUFFER_SIZE:]
                 signal_placeholder.line_chart(plot_data)
            else:
                 signal_placeholder.empty() # –û—á–∏—â–∞–µ–º –≥—Ä–∞—Ñ–∏–∫, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö

            # 4. –í–∏–¥–µ–æ–∫–∞–¥—Ä
            stframe.image(roi_display, channels="BGR", use_container_width=True)

            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ü–∏–∫–ª–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞–≤–∏—Å–∞–Ω–∏—è (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            # time.sleep(0.01)

        except KeyboardInterrupt:
            is_running = False
            print("–ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
        except Exception as e_main:
             print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e_main}")
             traceback.print_exc()
             try:
                 # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Streamlit, –µ—Å–ª–∏ –æ–Ω –µ—â–µ –¥–æ—Å—Ç—É–ø–µ–Ω
                 st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e_main}")
             except:
                 pass # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –º–æ–≥ —É–∂–µ "—É–ø–∞—Å—Ç—å"
             is_running = False # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ü–∏–∫–ª –ø—Ä–∏ —Å–µ—Ä—å–µ–∑–Ω–æ–π –æ—à–∏–±–∫–µ
             time.sleep(2) # –î–∞–µ–º –≤—Ä–µ–º—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—à–∏–±–∫—É –≤ –∫–æ–Ω—Å–æ–ª–∏

    # --- –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –†–µ—Å—É—Ä—Å–æ–≤ ---
    print("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ü–∏–∫–ª–∞, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤...")
    if cap is not None and cap.isOpened():
        cap.release()
        print("–ö–∞–º–µ—Ä–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞.")
    # –£ MediaPipe –Ω–µ—Ç —è–≤–Ω–æ–≥–æ close() –¥–ª—è FaceDetection
    print("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

# --- –ó–∞–ø—É—Å–∫ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    models_exist = any(os.path.exists(p) for p in NN_MODEL_PATHS.values() if p)
    if not models_exist:
         print("–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ù–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ –ù–° –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø—É—Ç—è–º!")
         print("–î–æ—Å—Ç—É–ø–Ω—ã –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã (POS, CHROM, ICA).")
         print("–£–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏ –≤ NN_MODEL_PATHS –≤ –∫–æ–¥–µ.")

    run_rppg_app()