# -*- coding: utf-8 -*-
# ==============================================================================
#         Streamlit –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è rPPG –ò–∑–º–µ—Ä–µ–Ω–∏—è –ü—É–ª—å—Å–∞ –≤ –†–µ–∞–ª—å–Ω–æ–º –í—Ä–µ–º–µ–Ω–∏
#      (–í—Å–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã) v12.1 - –ü–æ–ª–Ω—ã–π –ö–æ–¥ –°–∫–æ–ª—å–∑—è—â–µ–≥–æ –û–∫–Ω–∞
# ==============================================================================
import streamlit as st
import cv2
import numpy as np
import time
import collections
import mediapipe as mp
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.signal import find_peaks, butter, filtfilt, detrend
from sklearn.decomposition import FastICA
import traceback
import os
import warnings

# --- –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π ---
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
APP_TITLE = "rPPG –î–µ—Ç–µ–∫—Ç–æ—Ä –ü—É–ª—å—Å–∞ (–í—Å–µ –ú–µ—Ç–æ–¥—ã + –°–∫–æ–ª—å–∑—è—â–µ–µ –û–∫–Ω–æ –ù–°)"
WINDOW_SIZE_SEC = 10; FPS_ESTIMATED = 30; BUFFER_SIZE = WINDOW_SIZE_SEC * FPS_ESTIMATED
ROI_PADDING_FACTOR = 0.1; HR_WINDOW_SEC_ANALYSIS = 6; HR_MIN = 40; HR_MAX = 180
BANDPASS_LOW = 0.7; BANDPASS_HIGH = 4.0; MIN_DETECTION_CONFIDENCE = 0.6
HR_SMOOTHING_FACTOR = 0.3 # –§–∞–∫—Ç–æ—Ä —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –ß–°–° (0.0 - –±–µ–∑ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è, ~0.1-0.3 - —É–º–µ—Ä–µ–Ω–Ω–æ–µ)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ù–µ–π—Ä–æ—Å–µ—Ç–µ–π ---
NEURAL_NETWORKS = ['SimplePhysNet', 'ImprovedPhysNet', 'HAFNet', 'PhysFormer']
NN_MODEL_PATHS = { # <<< –£–ö–ê–ñ–ò–¢–ï –ü–†–ê–í–ò–õ–¨–ù–´–ï –ü–£–¢–ò –ö –í–ê–®–ò–ú .pth –§–ê–ô–õ–ê–ú! >>>
    'SimplePhysNet': 'SimplePhysNet_final.pth', # –ü—Ä–∏–º–µ—Ä: '/path/to/your/models/SimplePhysNet_final.pth'
    'ImprovedPhysNet': 'ImprovedPhysNet_final.pth',
    'HAFNet': 'HAFNet_final.pth',
    'PhysFormer': 'PhysFormer_final.pth',
}
NN_WINDOW_SIZE_FRAMES = 150  # –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –û–ë–£–ß–ï–ù–´ –º–æ–¥–µ–ª–∏ (–ù–ï –ú–ï–ù–Ø–¢–¨ –õ–ï–ì–ö–û–ú–´–°–õ–ï–ù–ù–û!)
# --- –®–∞–≥ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ –ù–° ---
# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –∫–∞–∂–¥—ã–µ N –∫–∞–¥—Ä–æ–≤ –ü–û–°–õ–ï –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –±—É—Ñ–µ—Ä–∞.
NN_SLIDE_STEP = 30           # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
NN_RESIZE_DIM = (64, 64)
PHYSNET_DROPOUT = 0.3
HAFNET_FEATURE_DIM = 32; HAFNET_TRANSFORMER_LAYERS = 1; HAFNET_TRANSFORMER_HEADS = 4; HAFNET_DROPOUT = 0.15
PHYSFORMER_FEATURE_DIM = 64; PHYSFORMER_TRANSFORMER_LAYERS = 2; PHYSFORMER_TRANSFORMER_HEADS = 4; PHYSFORMER_DROPOUT = 0.1

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# --- –ë–õ–û–ö: –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –§—É–Ω–∫—Ü–∏–∏ (–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –ß–°–°) ---
def normalize_signal_np(signal):
    if signal is None or signal.size == 0: return np.array([])
    mean_val = np.mean(signal); std_val = np.std(signal)
    if std_val < 1e-8: return signal - mean_val
    return (signal - mean_val) / std_val

def bandpass_filter(signal, fs, low=BANDPASS_LOW, high=BANDPASS_HIGH, order=4):
    if signal is None or signal.size < order * 3 + 1 or fs <= 0: return signal
    nyq = 0.5 * fs; low_f = max(0.01, low); high_f = min(nyq - 0.01, high)
    if low_f >= high_f: return signal
    low_norm = low_f / nyq; high_norm = high_f / nyq
    try:
        b, a = butter(order, [low_norm, high_norm], btype='band')
        y = filtfilt(b, a, signal, method="gust")
    except ValueError as e:
        # print(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {e}, –¥–ª–∏–Ω–∞ —Å–∏–≥–Ω–∞–ª–∞: {len(signal)}, fs: {fs}")
        return signal
    if np.isnan(y).any(): return signal
    return y

def calculate_hr(signal, fs, window_sec=HR_WINDOW_SEC_ANALYSIS, min_hr=HR_MIN, max_hr=HR_MAX):
    if signal is None or fs <= 0: return np.nan
    effective_window_samples = min(len(signal), int(window_sec * fs))
    if effective_window_samples < fs * 1.0: # –¢—Ä–µ–±—É–µ–º —Ö–æ—Ç—è –±—ã 1 —Å–µ–∫—É–Ω–¥—É –¥–∞–Ω–Ω—ã—Ö
         return np.nan

    segment = signal[-effective_window_samples:]
    min_dist = max(1, int(fs / (max_hr / 60.0))) if max_hr > 0 else 1

    hr = np.nan
    segment_std = np.std(segment)
    if not np.isnan(segment).any() and segment_std > 1e-6:
        try:
            segment_median = np.median(segment)
            peaks, _ = find_peaks(segment, distance=min_dist, height=segment_median)

            if len(peaks) > 1: # –ù—É–∂–Ω–æ —Ö–æ—Ç—è –±—ã 2 –ø–∏–∫–∞
                actual_segment_duration_sec = len(segment) / fs
                peaks_per_sec = len(peaks) / actual_segment_duration_sec if actual_segment_duration_sec > 0 else 0
                hr_calc = peaks_per_sec * 60.0
                if min_hr <= hr_calc <= max_hr:
                    hr = hr_calc
        except Exception as e:
            # print(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ß–°–°: {e}")
            pass
    return hr

# --- –ë–õ–û–ö: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ú–µ—Ç–æ–¥—ã (POS, CHROM, ICA) ---
def chrom_method(rgb_buffer):
    if rgb_buffer is None or rgb_buffer.shape[0]<2 or rgb_buffer.shape[1]!=3: return np.array([])
    std_rgb=np.std(rgb_buffer,axis=0,keepdims=True); std_rgb[std_rgb<1e-8]=1.0; RGB_std=rgb_buffer/std_rgb
    X=3*RGB_std[:,0]-2*RGB_std[:,1]; Y=1.5*RGB_std[:,0]+RGB_std[:,1]-1.5*RGB_std[:,2]
    std_X=np.std(X); std_Y=np.std(Y); alpha=std_X/(std_Y+1e-8) if std_Y>1e-8 else 1.0
    chrom_signal=X-alpha*Y;
    try: return detrend(chrom_signal)
    except ValueError: return chrom_signal - np.mean(chrom_signal)

def pos_method(rgb_buffer):
    if rgb_buffer is None or rgb_buffer.shape[0]<2 or rgb_buffer.shape[1]!=3: return np.array([])
    mean_rgb=np.mean(rgb_buffer,axis=0,keepdims=True); mean_rgb[mean_rgb<1e-8]=1.0; rgb_norm=rgb_buffer/mean_rgb
    try: rgb_detrended=detrend(rgb_norm,axis=0)
    except ValueError: rgb_detrended=rgb_norm-np.mean(rgb_norm,axis=0,keepdims=True)
    proj_mat=np.array([[0,1,-1],[-2,1,1]]); proj_sig=np.dot(rgb_detrended,proj_mat.T); std_dev=np.std(proj_sig,axis=0)
    if std_dev.shape[0]<2 or std_dev[0]<1e-8: alpha=1.0
    else: alpha=std_dev[1]/(std_dev[0]+1e-8)
    pos_signal=proj_sig[:,0]+alpha*proj_sig[:,1];
    try: return detrend(pos_signal)
    except ValueError: return pos_signal - np.mean(pos_signal)

def ica_method(rgb_buffer, fs_approx=30):
    if rgb_buffer is None or rgb_buffer.shape[0] < 3 or rgb_buffer.shape[1] != 3: return np.array([])
    try: rgb_detrended=detrend(rgb_buffer,axis=0)
    except ValueError: rgb_detrended=rgb_buffer-np.mean(rgb_buffer,axis=0,keepdims=True)
    n_components=3
    try: # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–Ω–≥–∞
        cov_matrix = np.cov(rgb_detrended.T)
        rank = np.linalg.matrix_rank(cov_matrix)
        n_components = max(1, rank)
    except Exception: pass # –ò—Å–ø–æ–ª—å–∑—É–µ–º n_components=3 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    if n_components == 1: # –ï—Å–ª–∏ —Ä–∞–Ω–≥ 1, ICA –Ω–µ –Ω—É–∂–µ–Ω
        stds = np.std(rgb_detrended, axis=0)
        if len(stds) > 0 and np.max(stds) > 1e-8:
            best_channel = rgb_detrended[:, np.argmax(stds)]
            try: return detrend(best_channel)
            except ValueError: return best_channel - np.mean(best_channel)
        else: return np.zeros(rgb_buffer.shape[0])

    S_ = np.array([])
    try:
        ica = FastICA(n_components=n_components, random_state=42, max_iter=250, tol=0.08, whiten='unit-variance')
        S_ = ica.fit_transform(rgb_detrended)
        if S_.shape[1] != n_components:
             # print(f"Warning ICA: –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—ã—Ö–æ–¥–∞ ICA ({S_.shape[1]} != {n_components})")
             return np.array([])
    except Exception as e:
        # print(f"Warning ICA fit_transform: {e}")
        return np.array([])

    best_idx=-1; max_power=-1; low_f=BANDPASS_LOW; high_f=BANDPASS_HIGH
    for i in range(S_.shape[1]):
        sig=S_[:,i]
        if len(sig)<2 or np.std(sig)<1e-8: continue
        try:
            fft_win=sig*np.hanning(len(sig)); fft_v=np.fft.rfft(fft_win)
            fft_f=np.fft.rfftfreq(len(sig),1.0/fs_approx if fs_approx > 0 else 1.0/FPS_ESTIMATED)
            p_s=np.abs(fft_v)**2; mask=(fft_f>=low_f)&(fft_f<=high_f)
            if np.any(mask):
                p_band=np.mean(p_s[mask])
                if p_band > max_power: max_power=p_band; best_idx=i
        except Exception: continue

    if best_idx == -1: # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ FFT, –≤—ã–±–∏—Ä–∞–µ–º –ø–æ std
        stds = np.std(S_,axis=0)
        if len(stds) > 0 and np.max(stds) > 1e-8: best_idx = np.argmax(stds)
        else: return np.array([]) # –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å

    selected_component = S_[:, best_idx]
    try: return detrend(selected_component)
    except ValueError: return selected_component - np.mean(selected_component)


# --- –ë–õ–û–ö: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ú–æ–¥–µ–ª–µ–π –ù–µ–π—Ä–æ–Ω–Ω—ã—Ö –°–µ—Ç–µ–π ---
# (–í–ö–õ–Æ–ß–ï–ù–´ –í–°–ï –ö–õ–ê–°–°–´)
class SimplePhysNet(nn.Module):
    def __init__(self,in_channels=3,out_len=NN_WINDOW_SIZE_FRAMES): super().__init__(); self.encoder=nn.Sequential(nn.Conv3d(in_channels,32,(1,5,5),padding=(0,2,2)),nn.BatchNorm3d(32),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(32,64,(3,3,3),padding=1),nn.BatchNorm3d(64),nn.ReLU(),nn.MaxPool3d((1,2,2))); self.decoder=nn.Sequential(nn.Conv3d(64,1,kernel_size=1),nn.AdaptiveAvgPool3d((out_len,1,1)))
    def forward(self,x): x=self.encoder(x); x=self.decoder(x); x=x.squeeze(-1).squeeze(-1).squeeze(1); return x
class ImprovedPhysNet(nn.Module):
    def __init__(self,in_channels=3,out_len=NN_WINDOW_SIZE_FRAMES,dropout=PHYSNET_DROPOUT): super().__init__(); self.encoder=nn.Sequential(nn.Conv3d(in_channels,32,(1,5,5),padding=(0,2,2)),nn.BatchNorm3d(32),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(32,64,(3,3,3),padding=1),nn.BatchNorm3d(64),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(64,128,(3,3,3),padding=1),nn.BatchNorm3d(128),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Dropout3d(dropout)); self.decoder=nn.Sequential(nn.Conv3d(128,1,kernel_size=1),nn.AdaptiveAvgPool3d((out_len,1,1)))
    def forward(self,x): x=self.encoder(x); x=self.decoder(x); x=x.squeeze(-1).squeeze(-1).squeeze(1); return x
class PositionalEncoding(nn.Module):
    def __init__(self,d_model,max_len=512): super().__init__(); pos=torch.arange(max_len).unsqueeze(1); div=torch.exp(torch.arange(0,d_model,2)*(-np.log(10000.0)/d_model)); pe=torch.zeros(max_len,d_model); pe[:,0::2]=torch.sin(pos*div); pe[:,1::2]=torch.cos(pos*div); self.register_buffer('pe',pe)
    def forward(self,x): return x+self.pe[:x.size(1)].unsqueeze(0)
class PhysFormer3DStem(nn.Module):
    def __init__(self,in_channels=3,feature_dim=64): super().__init__(); self.feature_dim_arg = feature_dim; self.stem=nn.Sequential(nn.Conv3d(in_channels,16,(1,5,5),padding=(0,2,2)),nn.BatchNorm3d(16),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(16,32,(3,3,3),padding=1),nn.BatchNorm3d(32),nn.ReLU(),nn.MaxPool3d((1,2,2)),nn.Conv3d(32,feature_dim,(3,3,3),padding=1),nn.BatchNorm3d(feature_dim),nn.ReLU(),nn.AdaptiveAvgPool3d((None,1,1)))
    def forward(self,x): x=self.stem(x); x=x.squeeze(-1).squeeze(-1); x=x.permute(0,2,1); return x
class TemporalDifferenceModule(nn.Module):
    def __init__(self): super().__init__()
    def forward(self,x): diff=x[:,1:,:]-x[:,:-1,:]; diff=F.pad(diff,(0,0,1,0),"constant",0); return diff
class PhysFormer(nn.Module):
    def __init__(self,in_channels=3,feature_dim=PHYSFORMER_FEATURE_DIM,num_layers=PHYSFORMER_TRANSFORMER_LAYERS,num_heads=PHYSFORMER_TRANSFORMER_HEADS,dropout=PHYSFORMER_DROPOUT,max_len=NN_WINDOW_SIZE_FRAMES):
        super().__init__(); self.feat_ext=PhysFormer3DStem(in_channels,feature_dim); self.tdm=TemporalDifferenceModule(); self.pos_enc=PositionalEncoding(feature_dim,max_len)
        enc_l=nn.TransformerEncoderLayer(d_model=feature_dim,nhead=num_heads,dim_feedforward=feature_dim*2,dropout=dropout,activation='relu',batch_first=True)
        self.transformer=nn.TransformerEncoder(enc_l,num_layers=num_layers,norm=nn.LayerNorm(feature_dim)); self.head=nn.Sequential(nn.LayerNorm(feature_dim),nn.Linear(feature_dim,1))
    def forward(self,x): feat=self.feat_ext(x); diff=self.tdm(feat); diff_pos=self.pos_enc(diff); z=self.transformer(diff_pos); out=self.head(z); return out.squeeze(-1)
class HAFNet(nn.Module):
    def __init__(self,in_channels=3,feature_dim=HAFNET_FEATURE_DIM,nhead=HAFNET_TRANSFORMER_HEADS,num_encoder_layers=HAFNET_TRANSFORMER_LAYERS,dropout=HAFNET_DROPOUT,max_len=NN_WINDOW_SIZE_FRAMES):
        super().__init__(); self.cnn_stem=PhysFormer3DStem(in_channels,feature_dim); self.pos_enc=PositionalEncoding(feature_dim,max_len)
        enc_l=nn.TransformerEncoderLayer(d_model=feature_dim,nhead=nhead,dim_feedforward=feature_dim*2,dropout=dropout,activation='relu',batch_first=True)
        self.transformer_enc=nn.TransformerEncoder(enc_l,num_layers=num_encoder_layers,norm=nn.LayerNorm(feature_dim)); self.head=nn.Sequential(nn.LayerNorm(feature_dim),nn.Linear(feature_dim,1))
    def forward(self,x): feat=self.cnn_stem(x); feat_pos=self.pos_enc(feat); mem=self.transformer_enc(feat_pos); out=self.head(mem); return out.squeeze(-1)

# --- –§—É–Ω–∫—Ü–∏—è –ó–∞–≥—Ä—É–∑–∫–∏ –ú–æ–¥–µ–ª–µ–π –ù–° ---
def get_model_instance(model_name, model_path):
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ—Å–∞."""
    model_class_map = {
        "SimplePhysNet": SimplePhysNet, "ImprovedPhysNet": ImprovedPhysNet,
        "HAFNet": HAFNet, "PhysFormer": PhysFormer
    }
    model_class = model_class_map.get(model_name)
    if not model_class:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–∏ –¥–ª—è {model_name}")

    model = model_class().to(device)
    try:
        state_dict = torch.load(model_path, map_location=device)
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ 'module.'
        if all(k.startswith('module.') for k in state_dict.keys()):
             state_dict = {k[len('module.'):]: v for k, v in state_dict.items()}

        model_dict = model.state_dict()
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ —Å–ª–æ–∏
        state_dict = {k: v for k, v in state_dict.items() if k in model_dict and model_dict[k].size() == v.size()}
        if not state_dict:
             print(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö —Å–ª–æ–µ–≤ –≤ state_dict –¥–ª—è {model_name} –∏–∑ {model_path}")
             return None

        model_dict.update(state_dict)
        model.load_state_dict(model_dict, strict=False) # strict=False –ø–æ–ª–µ–∑–Ω–æ
        model.eval()
        print(f"  –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
        return model
    except FileNotFoundError:
        print(f"  –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {model_path}")
        return None
    except Exception as e:
        print(f"  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤ –¥–ª—è {model_name} –∏–∑ {model_path}: {e}")
        traceback.print_exc()
        return None


# --- –§—É–Ω–∫—Ü–∏—è –ó–∞–≥—Ä—É–∑–∫–∏ –†–µ—Å—É—Ä—Å–æ–≤ —Å –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º ---
@st.cache_resource
def load_resources():
    models = {}
    print("--- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –ù–° ---")
    for name in NEURAL_NETWORKS:
        path = NN_MODEL_PATHS.get(name)
        if not path:
            print(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è –º–æ–¥–µ–ª–∏ {name}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue

        model_file_exists = os.path.exists(path)
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ '{path}' –¥–ª—è –º–æ–¥–µ–ª–∏ {name}: {'–ù–∞–π–¥–µ–Ω' if model_file_exists else '–ù–ï –ù–ê–ô–î–ï–ù'}")

        if model_file_exists:
            model_instance = get_model_instance(name, path)
            if model_instance:
                models[name] = model_instance
        else:
            print(f"  –ü—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ {name}, —Ç.–∫. —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    print(f"--- –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(models)} –ù–° –º–æ–¥–µ–ª–µ–π ---")

    print("--- –ó–∞–≥—Ä—É–∑–∫–∞ MediaPipe ---")
    face_detector = None
    try:
        mp_face_detection = mp.solutions.face_detection
        face_detector = mp_face_detection.FaceDetection(min_detection_confidence=MIN_DETECTION_CONFIDENCE, model_selection=0)
        print("MediaPipe Face Detection —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MediaPipe: {e}")
        traceback.print_exc()
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å MediaPipe Face Detection: {e}. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å.")
        st.stop() # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º, –µ—Å–ª–∏ MP –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

    return models, face_detector

# --- –û—Å–Ω–æ–≤–Ω–∞—è –§—É–Ω–∫—Ü–∏—è –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
def run_rppg_app():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –†–µ—Å—É—Ä—Å–æ–≤ ---
    loaded_nn_models, face_detector = load_resources()
    available_methods = ["POS", "CHROM", "ICA"] + sorted(list(loaded_nn_models.keys()))
    if not available_methods: st.error("–û—à–∏–±–∫–∞: –ù–µ –¥–æ—Å—Ç—É–ø–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ rPPG."); return

    selected_method = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è:", available_methods, index=0, key="method_select")
    # –°–ª–∞–π–¥–µ—Ä –¥–ª—è —à–∞–≥–∞ –ù–° –≤—ã–Ω–µ—Å–µ–Ω —Å—é–¥–∞ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞—á–µ–Ω–∏—è
    nn_slide_step_option = st.sidebar.slider(
        "–®–∞–≥ —Å–∫–æ–ª—å–∂. –æ–∫–Ω–∞ –ù–° (–∫–∞–¥—Ä—ã):",
        min_value=5, max_value=NN_WINDOW_SIZE_FRAMES,
        value=NN_SLIDE_STEP, step=5, key="nn_stride",
        help="–ö–∞–∫ —á–∞—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ù–° –ø–æ—Å–ª–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –±—É—Ñ–µ—Ä–∞. –ú–µ–Ω—å—à–µ = —á–∞—â–µ, –Ω–æ –≤—ã—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞.",
        disabled=(selected_method not in loaded_nn_models) # –î–µ–ª–∞–µ–º –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–º –¥–ª—è –∫–ª–∞—Å—Å–∏–∫–∏
    )

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ö–∞–º–µ—Ä—ã ---
    cap = None
    camera_indices = [0, 1, 2]
    for idx in camera_indices:
        try:
            cap = cv2.VideoCapture(idx)
            if cap.isOpened():
                print(f"–í–µ–±-–∫–∞–º–µ—Ä–∞ —É—Å–ø–µ—à–Ω–æ –æ—Ç–∫—Ä—ã—Ç–∞ (–∏–Ω–¥–µ–∫—Å {idx}).")
                res_w = 640; res_h = 480 # –ü–æ–ø—ã—Ç–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
                if cap.set(cv2.CAP_PROP_FRAME_WIDTH, res_w) and cap.set(cv2.CAP_PROP_FRAME_HEIGHT, res_h): print(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã: {res_w}x{res_h}")
                else: print("–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã.")
                break
            else: cap.release(); cap = None
        except Exception as e: print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É {idx}: {e}"); cap = None
    if cap is None: st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–µ–±-–∫–∞–º–µ—Ä—É."); return

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë—É—Ñ–µ—Ä–æ–≤ –∏ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ session_state ---
    if 'initialized' not in st.session_state:
        st.session_state.mean_rgb_buffer = collections.deque(maxlen=BUFFER_SIZE)
        st.session_state.rppg_signal_buffer = collections.deque(maxlen=BUFFER_SIZE) # –î–ª—è –∫–ª–∞—Å—Å–∏–∫–∏
        st.session_state.timestamps = collections.deque(maxlen=BUFFER_SIZE)
        st.session_state.nn_frame_buffer = collections.deque(maxlen=NN_WINDOW_SIZE_FRAMES) # –î–ª—è –ù–°
        st.session_state.current_hr = np.nan
        st.session_state.last_fps_time = time.time()
        st.session_state.frame_count_for_fps = 0
        st.session_state.last_signal_time = time.time()
        st.session_state.nn_buffer_filled = False
        st.session_state.nn_frames_since_last_pred = 0
        st.session_state.last_method = selected_method
        st.session_state.initialized = True
        print("–°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ.")

    # –°–±—Ä–æ—Å –ø—Ä–∏ —Å–º–µ–Ω–µ –º–µ—Ç–æ–¥–∞
    if selected_method != st.session_state.last_method:
        print(f"–ú–µ—Ç–æ–¥ –∏–∑–º–µ–Ω–µ–Ω. –°–±—Ä–æ—Å –±—É—Ñ–µ—Ä–æ–≤ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ù–°.")
        st.session_state.mean_rgb_buffer.clear(); st.session_state.rppg_signal_buffer.clear()
        st.session_state.timestamps.clear(); st.session_state.nn_frame_buffer.clear()
        st.session_state.current_hr = np.nan; st.session_state.nn_buffer_filled = False
        st.session_state.nn_frames_since_last_pred = 0; st.session_state.last_method = selected_method
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–ª–∞–π–¥–µ—Ä–∞
        st.rerun() # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–ª–∞–π–¥–µ—Ä–∞

    # --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
    col1, col2 = st.columns([3, 1])
    with col1: stframe = st.empty()
    with col2:
        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –†–µ–∑—É–ª—å—Ç–∞—Ç")
        st.write(f"–ú–µ—Ç–æ–¥: **{selected_method}**")
        if selected_method in loaded_nn_models:
             st.write(f"–®–∞–≥ –ù–°: {nn_slide_step_option} –∫–∞–¥—Ä–æ–≤") # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —à–∞–≥
        hr_placeholder = st.empty(); hr_placeholder.metric("–¢–µ–∫—É—â–∏–π –ü—É–ª—å—Å (—É–¥/–º–∏–Ω)", "–û–∂–∏–¥–∞–Ω–∏–µ...")
        fps_placeholder = st.empty(); fps_placeholder.write("–ö–∞–º–µ—Ä–∞ FPS: ...")
        signal_placeholder = st.empty()
        status_placeholder = st.empty()

    # --- –ì–ª–∞–≤–Ω—ã–π –¶–∏–∫–ª ---
    is_running = True
    mp_duration = 0.0 # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ FPS
    print("–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    while is_running:
        loop_start_time = time.time()
        try:
            ret, frame = cap.read()
            if not ret or frame is None or frame.size == 0:
                status_placeholder.warning("–ü—Ä–æ–±–ª–µ–º–∞ —Å —á—Ç–µ–Ω–∏–µ–º –∫–∞–¥—Ä–∞...", icon="‚ö†Ô∏è"); time.sleep(0.1)
                continue

            current_time = time.time(); st.session_state.timestamps.append(current_time)

            # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ö–∞–¥—Ä–∞ (MediaPipe) ---
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_rgb.flags.writeable = False
            if frame_rgb.dtype != np.uint8: frame_rgb = frame_rgb.astype(np.uint8)
            mp_start_time = time.time()
            results = face_detector.process(frame_rgb)
            mp_duration = time.time() - mp_start_time # –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è MP
            frame_rgb.flags.writeable = True

            height, width, _ = frame.shape; face_found = False; roi_display = frame.copy()
            should_predict_nn = False # –§–ª–∞–≥: –Ω—É–∂–Ω–æ –ª–∏ –¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ù–°

            if results.detections:
                detection = sorted(results.detections, key=lambda x: x.score[0], reverse=True)[0]
                bboxC = detection.location_data.relative_bounding_box
                if bboxC and detection.score[0] > MIN_DETECTION_CONFIDENCE:
                    xmin=int(bboxC.xmin*width); ymin=int(bboxC.ymin*height); w=int(bboxC.width*width); h=int(bboxC.height*height)
                    pad_w=int(w*ROI_PADDING_FACTOR); pad_h=int(h*ROI_PADDING_FACTOR)
                    x1=max(0,xmin-pad_w); y1=max(0,ymin-pad_h); x2=min(width,xmin+w+pad_w); y2=min(height,ymin+h+pad_h)
                    if y2 > y1 and x2 > x1:
                        face_found = True; roi = frame[y1:y2, x1:x2]
                        # 1. –î–∞–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
                        mean_bgr_roi = np.mean(roi, axis=(0, 1))
                        st.session_state.mean_rgb_buffer.append(mean_bgr_roi[::-1])
                        st.session_state.last_signal_time = current_time

                        # 2. –î–∞–Ω–Ω—ã–µ –¥–ª—è –ù–° –º–µ—Ç–æ–¥–æ–≤ (–¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ–≥–¥–∞, –µ—Å–ª–∏ –º–µ—Ç–æ–¥ –ù–° –≤—ã–±—Ä–∞–Ω)
                        if selected_method in loaded_nn_models:
                            try:
                                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω –ù–° –º–µ—Ç–æ–¥
                                prep_start = time.time()
                                roi_resized_nn = cv2.resize(roi, NN_RESIZE_DIM, interpolation=cv2.INTER_LINEAR)
                                roi_norm = (roi_resized_nn / 255.0) * 2.0 - 1.0
                                roi_norm_transposed = roi_norm.transpose(2, 0, 1) # (C, H, W)
                                st.session_state.nn_frame_buffer.append(roi_norm_transposed) # –î–æ–±–∞–≤–ª—è–µ–º –≤ deque
                                # print(f"NN Prep time: {(time.time() - prep_start)*1000:.1f} ms")

                                # --- –õ–æ–≥–∏–∫–∞ –°–∫–æ–ª—å–∑—è—â–µ–≥–æ –û–∫–Ω–∞ ---
                                current_buffer_len = len(st.session_state.nn_frame_buffer)

                                if not st.session_state.nn_buffer_filled:
                                    if current_buffer_len == NN_WINDOW_SIZE_FRAMES:
                                        st.session_state.nn_buffer_filled = True
                                        should_predict_nn = True # –ü–µ—Ä–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                                        st.session_state.nn_frames_since_last_pred = 0
                                        status_placeholder.success("–ù–° –±—É—Ñ–µ—Ä –∑–∞–ø–æ–ª–Ω–µ–Ω, –ø–µ—Ä–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞...", icon="‚úÖ")
                                    else:
                                        status_placeholder.info(f"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ù–°: {current_buffer_len}/{NN_WINDOW_SIZE_FRAMES} –∫–∞–¥—Ä–æ–≤", icon="‚è≥")
                                else: # –ë—É—Ñ–µ—Ä —É–∂–µ –±—ã–ª –∑–∞–ø–æ–ª–Ω–µ–Ω
                                    st.session_state.nn_frames_since_last_pred += 1
                                    if st.session_state.nn_frames_since_last_pred >= nn_slide_step_option:
                                        should_predict_nn = True # –ü–æ—Ä–∞ –¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                                        st.session_state.nn_frames_since_last_pred = 0
                                        status_placeholder.success(f"–ù–° –æ–±—Ä–∞–±–æ—Ç–∫–∞ (—à–∞–≥ {nn_slide_step_option})...", icon="‚ö°")
                                    # –ú–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –ø–æ–∫–∞–∑–∞ –æ–∂–∏–¥–∞–Ω–∏—è
                                    # elif not should_predict_nn:
                                    #     remaining = nn_slide_step_option - st.session_state.nn_frames_since_last_pred
                                    #     status_placeholder.info(f"–ù–°: —Å–ª–µ–¥. —á–µ—Ä–µ–∑ {remaining} –∫.", icon="‚è≥")

                            except cv2.error as e_resize: pass # –û—à–∏–±–∫–∞ —Ä–µ—Å–∞–π–∑–∞/–æ–±—Ä–∞–±–æ—Ç–∫–∏

                        cv2.rectangle(roi_display, (x1, y1), (x2, y2), (0, 255, 0), 2)

            # --- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º, –µ—Å–ª–∏ –ª–∏—Ü–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ---
            if not face_found:
                 if st.session_state.nn_buffer_filled:
                      print("–õ–∏—Ü–æ –ø–æ—Ç–µ—Ä—è–Ω–æ, —Å–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –ù–° –±—É—Ñ–µ—Ä–∞.")
                      st.session_state.nn_buffer_filled = False # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏
                 st.session_state.nn_frames_since_last_pred = 0 # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ —à–∞–≥–∞
                 if time.time() - st.session_state.last_signal_time > 1.0:
                      status_placeholder.info("–õ–∏—Ü–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ...", icon="üö´")


            # --- –†–∞—Å—á–µ—Ç rPPG –°–∏–≥–Ω–∞–ª–∞ –∏ –ß–°–° ---
            calculated_hr_this_step = np.nan; actual_fps = FPS_ESTIMATED
            if len(st.session_state.timestamps) > 10:
                 time_diff = st.session_state.timestamps[-1] - st.session_state.timestamps[-10]
                 if time_diff > 0.01: actual_fps = 9 / time_diff
                 actual_fps = max(1.0, min(actual_fps, 60.0))

            signal_processed_success = False; current_rppg_signal_for_plot = None

            # --- –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã ---
            if selected_method in ["POS", "CHROM", "ICA"]:
                 min_len_classical = int(BUFFER_SIZE * 0.3);
                 if selected_method == "ICA": min_len_classical = int(BUFFER_SIZE * 0.7)
                 if len(st.session_state.mean_rgb_buffer) > min_len_classical:
                    rgb_data = np.array(st.session_state.mean_rgb_buffer); rppg_signal_raw = np.array([])
                    try: # –í—ã–∑–æ–≤ –º–µ—Ç–æ–¥–∞
                        if selected_method == "POS": rppg_signal_raw = pos_method(rgb_data)
                        elif selected_method == "CHROM": rppg_signal_raw = chrom_method(rgb_data)
                        elif selected_method == "ICA": rppg_signal_raw = ica_method(rgb_data, actual_fps)
                    except Exception as e_method: print(f"–û—à–∏–±–∫–∞ –º–µ—Ç–æ–¥–∞ {selected_method}: {e_method}")
                    if rppg_signal_raw is not None and rppg_signal_raw.size > 1: # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–∞
                        rppg_norm = normalize_signal_np(rppg_signal_raw); rppg_filt = bandpass_filter(rppg_norm, actual_fps)
                        if rppg_filt is not None and rppg_filt.size > 1: # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±—É—Ñ–µ—Ä–∞ rPPG
                            num_already = len(st.session_state.rppg_signal_buffer); num_expected = len(rgb_data); num_new = num_expected - num_already
                            if num_new > 0 and len(rppg_filt) >= num_new: st.session_state.rppg_signal_buffer.extend(rppg_filt[-num_new:])
                            elif len(rppg_filt) > num_already : st.session_state.rppg_signal_buffer.extend(rppg_filt[num_already:])
                            elif len(rppg_filt)>0 and num_already==0: st.session_state.rppg_signal_buffer.extend(rppg_filt)
                            signal_processed_success = True; current_rppg_signal_for_plot = np.array(st.session_state.rppg_signal_buffer)
                            min_len_hr = int(HR_WINDOW_SEC_ANALYSIS * actual_fps * 0.8) # –†–∞—Å—á–µ—Ç –ß–°–°
                            if len(st.session_state.rppg_signal_buffer) > min_len_hr:
                                hr_val = calculate_hr(current_rppg_signal_for_plot, actual_fps, window_sec=HR_WINDOW_SEC_ANALYSIS)
                                if not np.isnan(hr_val): calculated_hr_this_step = hr_val

            # --- –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã ---
            elif selected_method in loaded_nn_models:
                 if should_predict_nn: # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ?
                    rppg_signal_raw_nn = np.array([]); nn_predict_start_time = time.time()
                    try:
                        if len(st.session_state.nn_frame_buffer) == NN_WINDOW_SIZE_FRAMES: # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –±—É—Ñ–µ—Ä–∞
                            model_instance = loaded_nn_models[selected_method]
                            nn_input_numpy = np.array(st.session_state.nn_frame_buffer) # (T, C, H, W)
                            nn_input_permuted = nn_input_numpy.transpose(1, 0, 2, 3)     # (C, T, H, W)
                            input_tensor = torch.from_numpy(nn_input_permuted).float().unsqueeze(0).to(device) # (B=1, C, T, H, W)

                            with torch.no_grad(): rppg_signal_raw_nn = model_instance(input_tensor).squeeze().cpu().numpy()
                            nn_predict_duration = time.time() - nn_predict_start_time
                            print(f"NN ({selected_method}) prediction time: {nn_predict_duration:.3f}s")
                        else: print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ù–°, –Ω–æ –±—É—Ñ–µ—Ä –Ω–µ –ø–æ–ª–æ–Ω.")

                    except Exception as e_method: print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ù–° {selected_method}: {e_method}"); traceback.print_exc()

                    if rppg_signal_raw_nn is not None and rppg_signal_raw_nn.size > 1: # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–∞ –ù–°
                        rppg_norm_nn = normalize_signal_np(rppg_signal_raw_nn); rppg_filt_nn = bandpass_filter(rppg_norm_nn, actual_fps)
                        if rppg_filt_nn is not None and rppg_filt_nn.size > 1:
                            signal_processed_success = True; current_rppg_signal_for_plot = rppg_filt_nn
                            nn_window_sec = NN_WINDOW_SIZE_FRAMES / actual_fps if actual_fps > 5 else (NN_WINDOW_SIZE_FRAMES / FPS_ESTIMATED)
                            min_samples_hr = int(actual_fps * 1.5) # –†–∞—Å—á–µ—Ç –ß–°–° –∏–∑ –≤—ã—Ö–æ–¥–∞ –ù–°
                            if len(rppg_filt_nn) >= min_samples_hr:
                                hr_val = calculate_hr(rppg_filt_nn, actual_fps, window_sec=nn_window_sec)
                                if not np.isnan(hr_val): calculated_hr_this_step = hr_val
                 # –ï—Å–ª–∏ –Ω–µ –¥–µ–ª–∞–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —ç—Ç–æ–º —à–∞–≥–µ, –Ω–æ —Å–∏–≥–Ω–∞–ª —É–∂–µ –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Ä–∞–Ω–µ–µ (–¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞)
                 elif signal_processed_success is False and current_rppg_signal_for_plot is None and len(st.session_state.rppg_signal_buffer)>0 and st.session_state.last_method==selected_method :
                      # –ú–æ–∂–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Å–∏–≥–Ω–∞–ª –ù–°, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –∏ –º–µ—Ç–æ–¥ –Ω–µ –º–µ–Ω—è–ª—Å—è
                      # current_rppg_signal_for_plot = np.array(st.session_state.rppg_signal_buffer) # –ü—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –±—ã –º—ã —Å–æ—Ö—Ä–∞–Ω—è–ª–∏ –µ–≥–æ
                      pass # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫


            # --- –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∏ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ß–°–° ---
            smoothed_hr = st.session_state.current_hr
            if not np.isnan(calculated_hr_this_step):
                 if np.isnan(st.session_state.current_hr): smoothed_hr = calculated_hr_this_step
                 else: smoothed_hr = (HR_SMOOTHING_FACTOR * calculated_hr_this_step + (1 - HR_SMOOTHING_FACTOR) * st.session_state.current_hr)
                 st.session_state.current_hr = smoothed_hr # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ

            # --- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ---
            hr_display = f"{st.session_state.current_hr:.1f}" if not np.isnan(st.session_state.current_hr) else "..."
            hr_placeholder.metric("–¢–µ–∫—É—â–∏–π –ü—É–ª—å—Å (—É–¥/–º–∏–Ω)", hr_display)
            st.session_state.frame_count_for_fps += 1; elapsed_time = time.time() - st.session_state.last_fps_time
            if elapsed_time > 1.0: # –û–±–Ω–æ–≤–ª—è–µ–º FPS —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É
                display_fps = st.session_state.frame_count_for_fps / elapsed_time
                fps_placeholder.write(f"–ö–∞–º–µ—Ä–∞ FPS: {display_fps:.1f} | MP time: {mp_duration*1000:.1f} ms | –û–±—Ä. FPS: {actual_fps:.1f}")
                st.session_state.last_fps_time = time.time(); st.session_state.frame_count_for_fps = 0
            if signal_processed_success and current_rppg_signal_for_plot is not None and current_rppg_signal_for_plot.size > 10:
                 plot_data = current_rppg_signal_for_plot[-BUFFER_SIZE:] # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ö–≤–æ—Å—Ç
                 signal_placeholder.line_chart(plot_data)
            stframe.image(roi_display, channels="BGR", use_container_width=True)

        except KeyboardInterrupt:
            is_running = False
            print("\n–ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
            st.warning("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º", icon="‚ö†Ô∏è")
        except Exception as e_main:
            print(f"\n–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e_main}")
            traceback.print_exc()
            is_running = False
            try:
                error_msg = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞:\n{str(e_main)}\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ."
                st.error(error_msg, icon="üö®")
                status_placeholder.error("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...", icon="‚õî")
            except Exception as e_error:
                print(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e_error}")
            time.sleep(2)

    # --- –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –†–µ—Å—É—Ä—Å–æ–≤ ---
    print("\n=== –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ===")
    try:
        if face_detector:
            face_detector.close()
            print("MediaPipe Face Detection –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–∏ MediaPipe: {e}")

    try:
        if cap is not None:
            if cap.isOpened():
                cap.release()
                print("–í–µ–±-–∫–∞–º–µ—Ä–∞ —É—Å–ø–µ—à–Ω–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞")
            else:
                print("–í–µ–±-–∫–∞–º–µ—Ä–∞ —É–∂–µ –±—ã–ª–∞ –∑–∞–∫—Ä—ã—Ç–∞")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–∏ –∫–∞–º–µ—Ä—ã: {e}")

    # –û—á–∏—Å—Ç–∫–∞ CUDA –∫–µ—à–∞, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è
    if device.type == "cuda":
        try:
            torch.cuda.empty_cache()
            print("CUDA –∫–µ—à –æ—á–∏—â–µ–Ω")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ CUDA: {e}")

    print("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ\n")

# --- –ó–∞–ø—É—Å–∫ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
if __name__ == "__main__":
    print("\n=== –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è rPPG –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ===")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–µ–π
    missing_models = []
    for name, path in NN_MODEL_PATHS.items():
        if not path:
            print(f"‚ö†Ô∏è –ü—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è –º–æ–¥–µ–ª–∏ {name}")
            continue
        if not os.path.exists(path):
            missing_models.append(name)
            print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {name} ({path})")
        else:
            print(f"‚úì –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞: {name}")
    
    if missing_models and NEURAL_NETWORKS:
        print("\n‚ö†Ô∏è –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –°–ª–µ–¥—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ –ù–° –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã:")
        for model in missing_models:
            print(f"  - {model}")
        print("\n–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã (POS, CHROM, ICA) –æ—Å—Ç–∞–Ω—É—Ç—Å—è –¥–æ—Å—Ç—É–ø–Ω—ã.")
        print("–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ù–° –º–µ—Ç–æ–¥–æ–≤ —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏ –≤ NN_MODEL_PATHS.")
    
    print("\n–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    run_rppg_app()