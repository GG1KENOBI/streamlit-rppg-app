# Исследование методов извлечения сигнала дистанционной фотоплетизмографии (дФПГ) с использованием видеоанализа и глубокого обучения. Алгоритм STAF-Net

**Документация исследования для магистерской диссертации**

---

## Оглавление

1.  [Аннотация](#аннотация)
2.  [Введение](#введение)
    *   [Мотивация](#мотивация)
    *   [Постановка проблемы](#постановка-проблемы)
    *   [Цели исследования](#цели-исследования)
    *   [Задачи исследования](#задачи-исследования)
3.  [Описание набора данных](#описание-набора-данных)
4.  [Методология](#методология)
    *   [I. Предобработка данных (с MediaPipe)](#i-предобработка-данных-с-mediapipe)
    *   [II. Методы извлечения сигнала дФПГ](#ii-методы-извлечения-сигнала-дфпг)
        *   [A. Классические методы](#a-классические-методы)
            *   [1. Метод на основе цветности (CHROM)](#1-метод-на-основе-цветности-chrom)
            *   [2. Метод независимых компонент (ICA)](#3-метод-независимых-компонент-ica)
        *   [B. Методы глубокого обучения](#b-методы-глубокого-обучения)
            *   [1. PhysNet](#1-physnet)
            *   [2. PhysFormer](#2-physformer)
            *   [3. TSCAN](#3-tscan)
            *   [4. Исследуемый метод: STAF-Net (Spatio-Temporal Attention Fusion Network - Advanced)](#4-исследуемый-метод-staf-net-spatio-temporal-attention-fusion-network---advanced)
                *   [Мотивация и обоснование](#мотивация-и-обоснование-staf-net)
                *   [Детали архитектуры](#детали-архитектуры-staf-net)
                *   [Преимущества](#преимущества-staf-net)
                *   [Потенциальные недостатки](#потенциальные-недостатки-staf-net)
    *   [III. Процедура обучения моделей](#iii-процедура-обучения-моделей)
        *   [Функции потерь](#функции-потерь)
    *   [IV. Протокол оценки](#iv-протокол-оценки)
        *   [Расчет частоты сердечных сокращений (ЧСС)](#расчет-частоты-сердечных-сокращений-чсс)
        *   [Метрики оценки](#метрики-оценки)
5.  [Представление результатов](#представление-результатов)
6.  [Обсуждение](#обсуждение)
    *   [Анализ результатов и сравнение моделей](#анализ-результатов-и-сравнение-моделей)
    *   [Ограничения](#ограничения)
    *   [Будущая работа](#будущая-работа)
7.  [Заключение](#заключение)
8.  [Структура кода и использование](#структура-кода-и-использование)
9.  [Зависимости](#зависимости)

---

## 1. Аннотация

Дистанционная фотоплетизмография (дФПГ) позволяет бесконтактно оценивать жизненно важные показатели, такие как частота сердечных сокращений (ЧСС), путем анализа мельчайших изменений цвета кожи человека, регистрируемых стандартными камерами. В данном исследовании рассматриваются и сравниваются различные методы извлечения сигнала дФПГ из видеозаписей лиц. Мы реализуем и оцениваем классические методы обработки сигналов (CHROM, ICA) наряду с современными моделями глубокого обучения (PhysNet, PhysFormer, TSCAN). Основное внимание уделяется исследованию и оценке производительности продвинутой гибридной архитектуры **STAF-Net (Spatio-Temporal Attention Fusion Network - Advanced)**, которая сочетает в себе основу из 3D сверточной нейронной сети (СНС) для извлечения пространственных признаков, модули пространственно-временного внимания и Трансформер-кодировщик для надежного временного моделирования динамики сигнала дФПГ. Исследование включает тщательную предобработку данных с использованием MediaPipe для детекции лиц и выделения области интереса (ROI), за которой следуют процедуры обучения и оценки, не зависящие от испытуемых (subject-independent). Эффективность оценивается на основе метрик точности сигнала (Средняя Абсолютная Ошибка, Коэффициент корреляции Пирсона) и точности оценки ЧСС (Средняя Абсолютная Ошибка ЧСС, Среднеквадратичная ошибка ЧСС, Стандартное отклонение ошибки ЧСС, Коэффициент корреляции Пирсона ЧСС). Цель состоит в том, чтобы предоставить всестороннее сравнение и оценить эффективность STAF-Net в контексте извлечения сигнала дФПГ.

---

## 2. Введение

### Мотивация

Сердечно-сосудистое здоровье является критически важным аспектом общего благополучия. Мониторинг частоты сердечных сокращений (ЧСС) предоставляет ценную информацию о физиологическом состоянии, уровне стресса и физической форме. Традиционные методы часто требуют контактных датчиков (например, электродов ЭКГ, пульсоксиметров), что может быть неудобно, некомфортно или непрактично в определенных сценариях (например, мониторинг младенцев, пациентов с ожогами, телемедицина, мониторинг водителей). Дистанционная фотоплетизмография (дФПГ) предлагает привлекательную альтернативу, используя повсеместно распространенные камеры (смартфоны, веб-камеры) для дистанционной и неинвазивной оценки ЧСС. Развитие таких технологий актуально для телемедицины, систем умного дома и персональных ассистентов здоровья, способствуя ранней диагностике и улучшению доступности медицинской помощи.

### Постановка проблемы

Извлечение слабого сигнала дФПГ из видео является сложной задачей из-за различных источников шума: изменений освещенности, движений головы, мимики, шума сенсора камеры и индивидуальных различий в тоне кожи. Основной сигнал пульсации объема крови (BVP - Blood Volume Pulse), отражающий сердечно-сосудистую активность, вызывает едва заметные изменения в поглощении и отражении света кожей. Основная проблема заключается в разработке надежных алгоритмов, способных точно изолировать этот тонкий, связанный с BVP, сигнал из зашумленных видеоданных.

### Цели исследования

1.  Реализовать и оценить устоявшиеся классические методы извлечения сигнала дФПГ (CHROM, ICA).
2.  Реализовать и оценить репрезентативные методы дФПГ на основе глубокого обучения (PhysNet, PhysFormer, TSCAN).
3.  Детально исследовать и оценить производительность продвинутой гибридной архитектуры нейронной сети, STAF-Net (Advanced), предназначенной для эффективного улавливания как пространственных, так и временных характеристик сигнала дФПГ из видеоданных.
4.  Провести систематическое сравнение всех реализованных методов на общем наборе данных MCD-rPPG с использованием стандартизированной предобработки и метрик оценки.
5.  Проанализировать сильные и слабые стороны каждого подхода, уделяя особое внимание производительности исследуемой модели STAF-Net (Advanced).

### Задачи исследования

1.  **Сбор и подготовка данных:** Использовать публичный набор данных MCD-rPPG, содержащий видеозаписи лиц, синхронизированные с эталонными сигналами PPG.
2.  **Конвейер предобработки:** Разработать надежный конвейер с использованием MediaPipe для детекции лиц, извлечения области интереса (ROI), нарезки на клипы, изменения размера и синхронизации с целевыми PPG сигналами.
3.  **Реализация методов:** Реализовать математические формулировки методов CHROM и ICA. Реализовать архитектуры нейронных сетей для PhysNet, PhysFormer, TSCAN и STAF-Net (Advanced) с использованием PyTorch.
4.  **Обучение моделей:** Обучить модели глубокого обучения на предобработанных данных с использованием разделения, не зависящего от испытуемых, для обеспечения обобщающей способности. Использовать функцию потерь NegPearson и оптимизатор Adam.
5.  **Оценка и сравнение:** Оценить все методы на отложенной тестовой выборке. Рассчитать метрики точности сигнала (MAE, Корреляция) и точности оценки ЧСС (MAE, RMSE, STD_Error, PCC). Сравнить производительность всех методов.
6.  **Анализ и документирование:** Проанализировать результаты, обсудить различия в производительности, преимущества и ограничения, а также задокументировать весь процесс исследования и полученные выводы.

---

## 3. Описание набора данных

В исследовании используется публично доступный датасет **MCD-rPPG (Multi-Camera Dataset for rPPG)**.
Ключевые характеристики датасета:
*   **Участники:** 600 испытуемых.
*   **Условия:** Для каждого испытуемого измерения проводились до и после физической нагрузки.
*   **Видеозаписи:** Для каждого измерения (состояния) производилась одновременная трехминутная видеозапись лица с трех различных ракурсов камерами разного типа.
*   **Физиологические сигналы:** Синхронно с видео записывались фотоплетизмограммы (PPG) с помощью контактного пульсоксиметра и электрокардиограммы (ЭКГ).
*   **Объем:** Всего датасет содержит 3600 видеозаписей (600 испытуемых × 2 состояния × 3 камеры) и соответствующие им PPG и ЭКГ сигналы.
*   **Вариативность:** Записи производились в разное время суток, в различных помещениях и при различном освещении, что обеспечивает разнообразие условий.
*   **Дополнительные данные:** Для каждого испытуемого доступны антропометрические и некоторые медицинские параметры (пол, возраст, рост, вес, ИМТ, уровень стресса, гемоглобин, АД, пульс, сатурация и др.), часть из которых также измерялась до и после нагрузки.

Эталонный PPG сигнал используется для обучения моделей глубокого обучения и для расчета эталонной ЧСС при оценке всех методов. В данном исследовании, ЧСС, указанная в метаданных датасета (`pulse`), также используется как целевое значение для оценки моделей.

---

## 4. Методология

### I. Предобработка данных (с MediaPipe)

Предобработка видеоданных является критически важным этапом для успешного извлечения сигнала дФПГ. В данном исследовании используется следующий пайплайн (реализован в ячейке 9 ноутбука):
1.  **Загрузка видео и метаданных:** Исходные видео и файл `db.csv` с метаданными загружаются из репозитория датасета MCD-rPPG. LFS-объекты (видео) подтягиваются при необходимости.
2.  **Детекция и вырезание области лица (ROI):** Для каждого кадра видео с помощью библиотеки **MediaPipe Face Detection** определяется область лица. Используемые параметры: `model_selection=0`, `min_detection_confidence=0.5`.
3.  **Нарезка на клипы:** Длинные видеозаписи нарезаются на короткие клипы фиксированной длины (`CLIP_LENGTH_FRAMES = 150`). Используются непересекающиеся клипы.
4.  **Изменение размера кадров:** Вырезанные области лиц приводятся к единому размеру (`IMG_SIZE_H, IMG_SIZE_W = 128, 128`).
5.  **Синхронизация и обработка PPG:** Эталонные PPG сигналы, соответствующие каждому видеоклипу, извлекаются и ресемплируются до длины клипа. Сигналы PPG нормализуются (вычитание среднего и деление на стандартное отклонение).
6.  **Сохранение данных:** Обработанные видеоклипы (`.npy`) и PPG сегменты (`.npy`) сохраняются. Информация о путях и метаданные сохраняются в CSV файл.
7.  **Разделение данных:** Клипы разделяются на обучающую и валидационную выборки по ID пациентов (80% обучение, 20% валидация).

### II. Методы извлечения сигнала дФПГ

#### A. Классические методы

Реализованы в ячейке 8 ноутбука.
1.  **Метод на основе зеленого канала (Green Channel):** Использует среднюю интенсивность пикселей зеленого канала ROI.
2.  **Метод на основе цветности (CHROM):** Комбинирует стандартизированные RGB каналы для формирования сигнала, более устойчивого к изменениям освещения.
    *   `X_chrom = 3*R_norm - 2*G_norm`
    *   `Y_chrom = 1.5*R_norm + G_norm - 1.5*B_norm`
    *   `rPPG = X_f - alpha * Y_f`, где `X_f`, `Y_f` - отфильтрованные `X_chrom`, `Y_chrom`, а `alpha = std(X_f) / (std(Y_f) + ε)`.
3.  **Метод независимых компонент (ICA):** Применяет `sklearn.decomposition.FastICA` к временным рядам средних RGB каналов. Компонента с максимальной спектральной мощностью в диапазоне ЧСС выбирается как дФПГ.

Все сигналы фильтруются полосовым фильтром (0.75-4.0 Гц).

#### B. Методы глубокого обучения

Определения моделей находятся в файле `dl_models.py` и импортируются/используются в соответствующих ячейках ноутбука.

##### 1. PhysNet
*   **Архитектура (ячейка 10 ноутбука):** Основана на 3D сверточных нейронных сетях. Включает последовательность блоков `ConvBlock` (3D свертка, BatchNorm3d, ReLU), слоев `MaxPool3d` (пространственный и пространственно-временной пулинг) и слоев апсемплинга (`ConvTranspose3d`). Завершается адаптивным пространственным пулингом (`AdaptiveAvgPool3d`) и финальной 3D сверткой. Используется Dropout для регуляризации.

##### 2. PhysFormer
*   **Архитектура (ячейка 12 ноутбука):** Гибридная модель.
    *   **CNN Backbone:** Начальные 3D сверточные блоки и пулинги, аналогичные PhysNet, для извлечения пространственно-временных признаков.
    *   **Transformer Encoder:** После агрегации пространственных признаков и добавления позиционного кодирования (`PositionalEncodingBatchFirst`), последовательность признаков обрабатывается несколькими слоями Transformer Encoder (`nn.TransformerEncoderLayer`, `nn.TransformerEncoder`) для моделирования временных зависимостей.
    *   **Голова предсказания:** Линейный слой и, при необходимости, апсемплинг для получения rPPG сигнала.

##### 3. TSCAN (Temporal Shift Convolutional Attention Network)
*   **Архитектура (ячейка 13 ноутбука, `dl_models.py`):**
    *   **CNN Backbone:** Стек 3D сверточных блоков и пулингов.
    *   **Temporal Shift Module (TSM):** Модуль `TemporalShift` сдвигает часть каналов признаков во времени, позволяя последующим 1D сверткам эффективно учитывать временной контекст.
    *   **Temporal Convolutional Network:** Сеть из 1D сверток (`nn.Conv1d`), ReLU и BatchNorm1d для анализа временных паттернов.
    *   **Upsampling:** При необходимости.

##### 4. Исследуемый метод: STAF-Net (Spatio-Temporal Attention Fusion Network - Advanced)
*   **Расшифровка:** Пространственно-Временная Сеть с Объединением Внимания (Продвинутая версия).
*   **Мотивация и обоснование (ячейка 13 ноутбука, `dl_models.py`):**
    STAF-Net разработана для комплексного извлечения дФПГ сигнала путем интеграции сильных сторон различных подходов: глубоких сверточных сетей для иерархического извлечения признаков, механизмов временного сдвига для локального временного моделирования, явных модулей пространственно-временного внимания для фокусировки на информативных областях, и трансформера для улавливания глобальных временных зависимостей.
*   **Детали архитектуры:**
    1.  **Начальные свертки и пулинг:** `initial_conv` (3D свертка 1x7x7, stride 1x2x2), `initial_pool` (MaxPool3D 1x3x3, stride 1x2x2).
    2.  **CNN Backbone:** Несколько стадий `ResidualBlock3D` (3D ResNet-подобные блоки). *В текущей реализации TSM явно не интегрирован в эти блоки.*
    3.  **CBAM-like Spatio-Temporal Attention (`CBAMLikeSpatialTemporalAttention`):** Применяет последовательно канальное внимание (`ChannelAttention`) и совместное пространственно-временное внимание (с использованием 3D свертки `spatial_conv`).
    4.  **Spatial Pooling:** `AdaptiveAvgPool3d` для агрегации пространственных признаков.
    5.  **Transformer Path:** Признаки проецируются (`input_projection_transformer`), добавляется позиционное кодирование (`PositionalEncodingBatchFirst`), и они обрабатываются `TransformerEncoder`.
    6.  **Prediction Head:** Несколько 1D сверточных слоев (`nn.Conv1d`) с ReLU и BatchNorm1d.
    7.  **Upsampling:** При необходимости.
*   **Преимущества (ожидаемые):**
    *   Эффективное извлечение иерархических пространственно-временных признаков.
    *   Фокусировка на релевантных областях и временных сегментах благодаря механизмам внимания.
    *   Моделирование как локальных (через TSM, если бы был активен в ResBlock, или через свертки), так и глобальных (Transformer) временных зависимостей.
*   **Потенциальные недостатки:**
    *   Высокая вычислительная сложность и большое количество параметров.
    *   Требует тщательной настройки гиперпараметров.

### III. Процедура обучения моделей

1.  **Разделение данных:** По ID пациентов (80% обучение, 20% валидация).
2.  **Загрузчики данных:** `DataLoader` с кастомной `collate_fn_skip_none_with_meta`.
3.  **Оптимизатор:** Adam.
4.  **Скорость обучения:** Например, 1e-4 для PhysNet, 1e-5 для PhysFormer.
5.  **Количество эпох:** Варьируется (10 для PhysNet, 29 для PhysFormer).
6.  **Сохранение лучшей модели:** По наименьшему значению функции потерь на валидационной выборке.
7.  **Устройство:** GPU с `nn.DataParallel` при наличии нескольких GPU.

#### Функции потерь

*   **NegPearson (Отрицательная корреляция Пирсона):** Основная функция потерь. Минимизирует `1 - r`, где `r` - коэффициент корреляции Пирсона между предсказанным и эталонным дФПГ сигналами. Это способствует обучению модели воспроизводить форму волны.

### IV. Протокол оценки

#### Расчет частоты сердечных сокращений (ЧСС)

1.  **Нормализация и фильтрация:** Предсказанные и эталонные сигналы нормализуются (z-score) и проходят полосовую фильтрацию (0.75-4.0 Гц).
2.  **FFT:** К отфильтрованному сигналу применяется Быстрое Преобразование Фурье.
3.  **Доминирующая частота:** В диапазоне 0.75-4.0 Гц находится частота с максимальной спектральной мощностью.
4.  **ЧСС:** Доминирующая частота (Гц) * 60 = ЧСС (уд/мин).
Эталонная ЧСС берется из метаданных датасета (`pulse`) или рассчитывается по эталонному PPG.

#### Метрики оценки

1.  **Средняя Абсолютная Ошибка (MAE) для ЧСС:** `(1/N) * Σ |HR_pred - HR_gt|`
2.  **Среднеквадратичная ошибка (RMSE) для ЧСС:** `sqrt((1/N) * Σ (HR_pred - HR_gt)^2)`
3.  **Стандартное отклонение ошибки (STD_Error) для ЧСС.**
4.  **Коэффициент корреляции Пирсона (PCC) для ЧСС.**
5.  **(Опционально для сигнала) MAE и PCC между предсказанным и эталонным rPPG/PPG сигналами.**

---

## 5. Представление результатов

*   Таблицы с усредненными метриками (MAE, RMSE, STD_Error, PCC для ЧСС) для каждого метода на тестовой выборке.
*   Графики потерь для моделей глубокого обучения (Train Loss, Validation Loss по эпохам).
*   Визуализации предсказанных дФПГ сигналов и ЧСС в сравнении с эталонными для иллюстративных примеров.

*В ноутбуке показаны графики потерь для PhysNet и PhysFormer, а также примеры предсказанных сигналов с рассчитанными ЧСС. Итоговые метрики ЧСС (MAE, MedianAE, STD MAE, PCC) выводятся для этих моделей.*

---

## 6. Обсуждение

### Анализ результатов и сравнение моделей

*На основе текущих результатов из ноутбука:*
*   **Классические методы (ячейка 8, была прервана):** Предварительные запуски показывают, что эти методы могут давать базовые предсказания, но их точность, вероятно, будет ниже, чем у глубоких моделей, особенно при наличии артефактов.
*   **PhysNet и PhysFormer (ячейки 10, 12):** Обе модели показали признаки обучения, но не достигли высокой точности в предсказании ЧСС (MAE около 27 bpm для обеих) за предоставленное количество эпох и с текущими гиперпараметрами. Валидационный лосс для обеих моделей стагнировал на уровне около 0.9-1.0 (для NegPearson, где 0 - идеальная корреляция, 2 - идеальная антикорреляция). Это указывает либо на необходимость более длительного обучения, либо на проблемы с переобучением/недообучением, либо на то, что модели "застряли" в локальном минимуме.
*   **TSCAN и STAF-Net (Advanced) (ячейка 13):** Обучение не было завершено в предоставленном выводе. От STAF-Net (Advanced) ожидается потенциально лучшая производительность за счет более сложной архитектуры, сочетающей различные подходы к извлечению признаков и моделированию зависимостей.

**Общий вывод по текущим экспериментам:** Извлечение точного дФПГ сигнала является сложной задачей. Текущие запуски моделей глубокого обучения требуют дальнейшей оптимизации для достижения конкурентоспособных результатов.

### Ограничения

1.  **Продолжительность обучения и настройка гиперпараметров:** Глубокие модели, особенно сложные как STAF-Net, требуют значительного времени на обучение и тщательного подбора гиперпараметров. Результаты в ноутбуке могут быть нерепрезентативны из-за ограниченного числа эпох или неоптимальных настроек.
2.  **Качество данных и синхронизация:** Возможны неточности в синхронизации видео и эталонных PPG, а также шумы в самих PPG сигналах.
3.  **Вычислительные ресурсы:** Могли ограничить возможность проведения исчерпывающего обучения.
4.  **Метрики оценки:** Фокус на ЧСС не полностью отражает качество формы волны.
5.  **Обобщающая способность:** Оценка на одном датасете.

### Будущая работа

1.  **Полное обучение и настройка STAF-Net (Advanced) и TSCAN:** Провести обучение на большем количестве эпох, подобрать оптимальные гиперпараметры.
2.  **Анализ компонентов STAF-Net:** Исследовать вклад каждого модуля (CNN, Attention, Transformer) в итоговую производительность.
3.  **Исследование различных функций потерь:** В том числе частотно-взвешенных или основанных на динамическом искажении времени (DTW).
4.  **Аугментация данных:** Для повышения робастности моделей.
5.  **Кросс-датасетная валидация:** Для оценки обобщающей способности.

---

## 7. Заключение

В данном исследовании был проведен анализ и реализация набора классических и глубоких методов для извлечения сигнала дФПГ. Предварительные результаты для моделей PhysNet и PhysFormer указывают на сложность задачи и необходимость дальнейшей оптимизации. Основной фокус дальнейшей работы будет направлен на полное обучение и оценку более продвинутых архитектур, таких как TSCAN и, в особенности, STAF-Net (Advanced), которая благодаря своей гибридной природе и использованию механизмов внимания и трансформеров, имеет потенциал для достижения более высоких и робастных результатов на датасете MCD-rPPG.

---

## 8. Структура кода и использование

Код исследования представлен в Jupyter ноутбуке (`notebook_diplom.ipynb`) и Python файле `dl_models.py`.
*   **`notebook_diplom.ipynb`:** Содержит ячейки для установки зависимостей, загрузки данных, предобработки (ячейка 9 - основная для глубоких моделей), определения и запуска классических методов (ячейка 8), а также определения, обучения и оценки моделей глубокого обучения: PhysNet (ячейка 10), PhysFormer (ячейка 12), TSCAN и STAF-Net (Advanced) (ячейка 13).
*   **`dl_models.py`:** Содержит классовые определения архитектур нейронных сетей PhysNet, PhysFormer, TSCAN, STAFNet_Advanced и их вспомогательных модулей.

**Порядок использования:**
1.  Установить зависимости.
2.  Запустить ячейки ноутбука для загрузки данных.
3.  Выполнить ячейку 9 для предобработки видео и создания клипов/PPG сегментов.
4.  Последовательно запускать ячейки с реализацией и обучением/оценкой интересующих методов.

Результаты (сохраненные модели, графики, CSV с метриками) сохраняются в директории, указанные в конфигурации каждой модели.

---

## 9. Зависимости

*   Python 3.x
*   PyTorch, torchvision, torchaudio
*   MediaPipe
*   Pandas
*   OpenCV-Python
*   Scikit-learn
*   tqdm
*   Matplotlib
*   SciPy
*   einops (для некоторых моделей, если используется)
*   datasets (Hugging Face)
*   NumPy

---
